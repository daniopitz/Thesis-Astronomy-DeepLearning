\secnumbersection{MARCO CONCEPTUAL}

\subsection{Propósito y Alcance del Capítulo}

Este capítulo establece las bases físicas, observacionales y computacionales necesarias para comprender, diseñar y validar DRAFTS++. Cumple una función dual crítica: por un lado, proporciona el contexto científico necesario para entender el problema de la detección de FRBs, y por otro, justifica las decisiones arquitectónicas y metodológicas adoptadas en el desarrollo del sistema.

Los objetivos principales incluyen: (1) contextualizar científicamente qué son los FRBs y su relevancia astronómica, (2) fundamentar técnicamente cómo funcionan los pipelines actuales y sus limitaciones, especialmente en alta frecuencia, (3) justificar metodológicamente por qué los enfoques de machine learning representan una evolución necesaria, y (4) establecer el marco de referencia para estándares, formatos de datos y criterios de evaluación.

Las preguntas guía que orientan este marco son: ¿Qué son los FRBs y por qué son importantes? ¿Cómo funcionan los pipelines actuales de detección? ¿Qué desafíos plantea la alta frecuencia? ¿Cómo este marco fundamenta las decisiones de arquitectura, entrenamiento y validación del pipeline?

En síntesis, el capítulo fija las coordenadas conceptuales que permiten transitar desde la fenomenología de las ráfagas rápidas de radio hasta las decisiones técnicas adoptadas en DRAFTS++. Cada sección se conecta con los requisitos que luego se materializan en el diseño, entrenamiento y validación del pipeline, asegurando que la discusión tecnológica repose sobre fundamentos astrofísicos sólidos.

\subsection{Fundamentos Físicos de los FRBs: Origen, Propiedades y Fenomenología Observacional}

\subsubsection{Definición y Características Observacionales: Energética, Dispersión y Tipología}

En radioastronomía, además de las fuentes permanentes o de emisión continua, existe una variedad de fenómenos transitorios caracterizados por emisiones de corta duración. Estos eventos incluyen los pulsos emitidos por púlsares y magnetares (señales periódicas o esporádicas de origen galáctico) y estallidos únicos o poco frecuentes como los Rotating Radio Transients (RRATs) y las recientemente descubiertas ráfagas rápidas de radio (\textit{Fast Radio Bursts}, FRBs) \citep{Petroff_2022}.

Los FRBs son pulsos de radio altamente energéticos ($10^{36}$--$10^{41}$\,erg) con duraciones que van desde microsegundos hasta milisegundos, provenientes de fuentes extragalácticas \citep{Lorimer2007}. Típicamente muestran un espectro de frecuencia amplio (decenas a cientos de MHz de ancho de banda) y una alta brillantitud, emitiendo una energía del orden de $10^{38}$--$10^{40}$\,erg en pocos milisegundos \citep{Petroff_2022}.

Presentan una marcada dispersión temporal: las frecuencias más bajas del pulso llegan más tarde que las altas, siguiendo la ley de dispersión en plasma $\Delta t \propto \mathrm{DM}\,\nu^{-2}$. Este retardo se manifiesta como una curvatura característica en datos frecuencia-tiempo, cuantificada por la DM, columna integrada de electrones libres a lo largo de la línea de visión \citep{LorimerKramer2004}. Las FRBs descubiertas hasta ahora tienen DM que van desde $\sim$50 hasta varios miles de pc\,cm$^{-3}$, excediendo lo atribuible a la Vía Láctea. Muchas muestran altos grados de polarización lineal, e índices espectrales diversos \citep{CHIME2021}.

Basándose en su detección, los FRBs pueden categorizarse en dos tipos principales: \textit{one-offs}, que han sido detectados solo una vez, y \textit{repetidores}, que muestran actividad recurrente. Los estudios morfológicos de FRBs demuestran que los one-offs y repetidores tienen estructuras espectrales y temporales distintas \citep{Pleunis2021}, sugiriendo que provienen de poblaciones diferentes y potencialmente tienen orígenes distintos.

El amplio rango de propiedades observadas impulsa preguntas sobre su origen y evolución. Para comprender cómo se instaló el campo en la agenda científica es necesario revisar el primer hallazgo y la evolución de los catálogos, lo que da pie a la siguiente sección.

\subsubsection{Descubrimiento Histórico y Evolución del Campo: De la Ráfaga de Lorimer a Catálogos con Miles de Eventos}

El descubrimiento inicial de un FRB en 2007, conocido como la ráfaga de Lorimer, marcó un hito al detectar un pulso de $\sim$5 ms cuya intensidad y retardo por dispersión sugerían que provenía de fuera de nuestra galaxia \citep{Lorimer2007}. Se reporto este evento excepcional en la banda de 1.4\,GHz, con un DM de 375\,pc\,cm$^{-3}$, mucho mayor al esperado por el contenido de electrones en la Vía Láctea, lo que implicaba un origen cosmológico \citep{Lorimer2007,CordesMcLaughlin2003}.

Desde entonces, numerosos radiotelescopios y búsquedas ciegas han descubierto centenares de FRBs; catálogos recientes han consolidado varios miles de eventos y fuentes \citep{CHIME2021,CHIMEFRB_2021_Catalog1}. La evolución del campo ha sido extraordinaria: de un evento aislado a miles de detecciones, estableciendo los FRBs como una nueva clase de fenómenos astrofísicos extremos con implicancias cosmológicas significativas \citep{Petroff_2022}.

 El salto desde un único burst a catálogos con miles de eventos habilita estudios estadísticos sobre la población. Esto motiva describir la diversidad observacional (DM, RM, anchos, entornos) que hoy caracteriza al campo y que orienta estrategias de detección.

\subsubsection{Casos Emblemáticos de Repetidores: FRB 121102, FRB 20180916B y FRB 20190520B como Laboratorios de Referencia}

Un subconjunto de FRBs, en particular FRB\,121102, FRB\,20180916B y FRB\,20190520B, exhibe actividad repetitiva y entornos densos \citep{CHIME2021,Niu2022_FRB20190520B}. Estos objetos se han transformado en laboratorios de referencia, ya que permiten correlacionar propiedades temporales, espectrales y ambientales con modelos de emisión y canal de dispersión.

El FRB 121102 fue el primer repetidor confirmado \citep{Spitler2016}. Su localización precisa en una galaxia enana de baja metalicidad y formación estelar activa a $z = 0.19273(8)$ \citep{2017Natur.541...58C,Tendulkar2017}, junto a su asociación con una fuente de radio persistente, aportó evidencia sólida de que los FRBs pueden residir en entornos extremos y compactos. Estudios de cadencia revelaron periodicidades en su actividad: inicialmente 157 días \citep{2020MNRAS.495.3551R} y luego refinadas a 161.3 días con una ventana activa del $\sim$60\% \citep{cruces2020frb121102}. Su abundante producción de bursts lo convierte en un dataset de entrenamiento y validación idóneo para pipelines de detección, incluido nuestro DRAFTS++ \citep{zhang2024drafts}.

Por otro lado, FRB 20180916B exhibe periodicidad de 16.35 días con una ventana activa del $\sim$31\%, lo que facilita campañas coordinadas multi-longitud de onda \citep{CHIME_FRB_Collaboration_2020}. Por su parte, FRB 20190520B combina repetición con una fuente de radio persistente y alta DM extragaláctica, reforzando la conexión con entornos densos \citep{Niu2022_FRB20190520B}. Estos casos complementan a FRB 121102 y brindan contraste para estudiar cómo el entorno y la periodicidad condicionan la morfología de las ráfagas.

El perfil diverso de los repetidores genuinos sugiere la necesidad de modelos progenitores capaces de sostener actividad recurrente y entornos magnetizados. Esto conduce naturalmente a la discusión sobre magnetares y otros escenarios, tratada en la siguiente subsubsección.

\subsubsection{Progenitores y Mecanismos de Emisión: El Rol de los Magnetares y Escenarios Alternativos}

La identificación de progenitores de FRBs ha sido uno de los desafíos más importantes del campo. El descubrimiento de SGR 1935+2154 como fuente de un FRB galáctico \citep{Bochenek2020,CHIME_SGR2020} proporcionó la primera evidencia directa de que los magnetares pueden producir FRBs, estableciendo este modelo como el "leading case" para explicar al menos una fracción significativa de la población.

Los magnetares son estrellas de neutrones con campos magnéticos extremos ($B \sim 10^{14}$--$10^{15}$ G) que pueden producir emisiones de radio coherentes a través de mecanismos de reconexión magnética, choques magnetosféricos o erupciones de superficie \citep{Bochenek2020}. La evidencia de SGR 1935+2154, que produjo un FRB con propiedades similares a los extragalácticos, sugiere que los FRBs repetidores podrían originarse en magnetares jóvenes o en entornos magnetizados densos \citep{CHIME_SGR2020}.

Una de las explicaciones para el comportamiento periódico de los FRBs es un escenario de formación que involucra un sistema binario, donde la periodicidad surge del período orbital. Otra posibilidad, señalada específicamente para FRB 20180916B, es que la periodicidad se debe a la precesión de un magnetar \citep{Feng2024}. Aunque aún no conocemos el origen exacto de estos FRBs, su comportamiento periódico facilita las observaciones de seguimiento y las campañas multi-longitud de onda, permitiendo caracterizar su extensión de emisión y constreñir su fuente progenitora.

Otros escenarios propuestos incluyen sistemas binarios compactos, colapsos de estrellas masivas, y fusiones de objetos compactos, pero la evidencia observacional favorece actualmente el modelo de magnetar como mecanismo principal para la producción de FRBs \citep{Petroff_2022}.

\subsection{Magnetares como Laboratorio de Alta Frecuencia: Conexión entre Emisión Galáctica y FRBs Extragalácticos}

\subsubsection{Fundamentos de Magnetares: Campos Extremos y Emisión de Radio Coherente}

Los magnetares son estrellas de neutrones con campos magnéticos extremos ($B \sim 10^{14}$--$10^{15}$ G) que representan laboratorios únicos para estudiar física en condiciones extremas \citep{Bochenek2020}. Estas fuentes exhiben emisión de radio tanto coherente como incoherente, con variabilidad temporal y energética que las convierte en análogos ideales para entender los mecanismos de producción de FRBs.

La emisión de radio de magnetares puede ocurrir tanto en estados quiescentes como durante erupciones, proporcionando insights sobre los mecanismos de producción de transientes rápidos. La variabilidad observada en magnetares galácticos, especialmente durante períodos de alta actividad, ha establecido conexiones directas con la producción de FRBs \citep{CHIME_SGR2020}.

\subsubsection{Magnetar del Centro Galáctico (PSR J1745-2900): Emisión hasta 154 GHz en Entornos Extremos}

El magnetar del Centro Galáctico, PSR J1745-2900, representa un caso único para estudiar emisión de radio en entornos extremos \citep{Torne2015,Torne2017}. Ubicado a solo 0.1 pc del agujero negro supermasivo Sgr A*, este magnetar experimenta condiciones ambientales extraordinarias que incluyen campos magnéticos intensos, gas denso y radiación de alta energía.

Las observaciones de PSR J1745-2900 han revelado pulsos de radio hasta frecuencias de 154 GHz \citep{Torne2017}, demostrando la viabilidad de detectar emisión de magnetares en el régimen milimétrico. Más recientemente, observaciones con ALMA en modo phased han detectado pulsos a 86 GHz (Band 3), proporcionando evidencia directa de emisión de radio coherente de magnetares en alta frecuencia \citep{veracasanova2025}.

\subsubsection{Estado del Arte en Alta Frecuencia: Detecciones con ALMA y el Territorio Inexplorado de mm-wave}

Las observaciones de pulsos del magnetar del Centro Galáctico con ALMA han abierto nuevas perspectivas para la detección de FRBs en el régimen milimétrico \citep{veracasanova2025}. Este hallazgo se enmarca en una serie de resultados revisados que demuestran emisión coherente de magnetares en mm hasta 225--291\,GHz \citep{Torne2015,Torne2017}. En paralelo, para FRBs extragalácticos se han reportado detecciones robustas a 4--8\,GHz \citep{Gajjar2018,Bethapudi2023} y a 2.2--2.3\,GHz con instrumentación independiente \citep{Majid2021}, lo que respalda la prospección hacia bandas aún más altas aunque las detecciones confirmadas en mm siguen siendo un objetivo abierto.

Las ventajas del régimen milimétrico incluyen menor scattering y mayor resolución angular, mientras que las desventajas incluyen menor flujo esperado y supresión de la dispersión temporal. Estas tensiones instrumentales demandan estrategias de detección adaptadas a las características específicas del régimen milimétrico \citep{veracasanova2025} y representan requisitos que DRAFTS++ debe anticipar desde su diseño.

\subsection{Pipelines Clásicos de Búsqueda de Pulsos: Arquitectura, Técnicas y Desafíos Computacionales}

\subsubsection{Anatomía de un Pipeline Clásico: Del Voltaje Crudo a la Detección de Candidatos}

Encontrar un FRB es comparable a buscar una aguja en un pajar cósmico: las tecnologías actuales requieren procesar del orden de $10^{12}$ realizaciones de los datos para detectar un solo FRB. Dicho de otro modo, por cada FRB descubierto, hay que cribar varios exabytes de datos ruidosos, en tiempo real y bajo severas limitaciones de latencia. Esto ha llevado a optimizar al extremo cada componente del pipeline de búsqueda, desde la limpieza inicial de la señal hasta la confirmación final de candidatos.

Detectar FRBs en voluminosos datos de radiotelescopios es un reto significativo. Los métodos clásicos se basan en identificar pulsos dispersos mediante de-dispersión y umbrales de relación señal-ruido (SNR) \citep{CordesMcLaughlin2003}. Un pipeline de búsqueda de FRBs consta de varios componentes funcionales bien definidos, que aplican secuencialmente diferentes transformaciones y filtrados a los datos crudos del telescopio. A grandes rasgos, el flujo es el siguiente: los datos de voltajes provenientes del telescopio se convierten en espectros dinámicos (intensidad en función de tiempo y frecuencia). Sobre este flujo de datos se aplican, en tiempo real, técnicas de limpieza de interferencias (RFI) para mitigar señales artificiales terrestres. Luego, los datos se dedispersan—es decir, se corrige el retardo por plasma interestelar para múltiples valores de medida de dispersión (DM)—produciendo cientos o miles de series de tiempo posibles. A cada serie dedispersada se le aplica filtrado por coincidencia (\textit{matched filtering}) usando plantillas de pulsos de distintas anchuras para resaltar posibles FRBs. Esto genera un enorme número de candidatos (eventos por encima de umbral) que luego deben clasificarse para descartar falsos positivos. Finalmente, si un candidato es identificado como un FRB real, el pipeline dispara almacenamiento y alertas: guarda temporalmente los datos crudos de alta resolución y notifica a otros observatorios para seguimiento inmediato.

Los parámetros críticos incluyen el paso de DM, factores de downsampling, umbrales de SNR, y la latencia del procesamiento. La eficacia depende de la calidad del enmascaramiento de RFI y de la elección de parámetros, requiriendo tuning manual extensivo para optimizar el rendimiento en diferentes condiciones observacionales \citep{Ransom_2003}.

\subsubsection{Herramientas Establecidas: PRESTO, Heimdall y TransientX}

Las herramientas clásicas más utilizadas incluyen PRESTO (PulsaR Exploration and Search TOolkit) \citep{2011ascl.soft07017R}, que implementa un flujo estándar con rfifind, DDplan, prepsubband, y single\_pulse\_search.py. PRESTO proporciona dedispersión exhaustiva sobre una malla de DM con optimizaciones para búsquedas de pulsares binarios y transientes \citep{Ransom_2003}.

Heimdall representa una implementación GPU-acelerada que utiliza dedispersión directa, tree y sub-band para acelerar la búsqueda de pulsos únicos \citep{Barsdell_2012}. Esta herramienta aprovecha la paralelización en GPU para reducir significativamente el tiempo de procesamiento, especialmente para búsquedas con grandes rangos de DM.

TransientX constituye un paquete moderno de alto rendimiento para búsquedas de single-pulse, diseñado específicamente para procesamiento eficiente de grandes volúmenes de datos \citep{2024A&A...683A.183M}.

\subsubsection{Mitigación de Interferencia de Radiofrecuencia (RFI): Técnicas desde Máscaras Estáticas hasta Métodos Estadísticos Avanzados}

El primer obstáculo en cualquier búsqueda de FRBs es la abundancia de interferencia de radiofrecuencia (RFI) de origen humano que contamina los datos. Las señales artificiales—provenientes de comunicaciones, radares, satélites, dispositivos electrónicos—suelen ser mucho más intensas que los tenues pulsos astrofísicos y, por lo tanto, pueden enmascarar o imitar falsamente a un FRB. Dado que cualquier señal no astrofísica se considera RFI en radioastronomía, se han desarrollado numerosas estrategias para identificar y filtrar estas interferencias sin eliminar las posibles señales cósmicas de interés.

La RFI puede clasificarse a grandes rasgos en dos tipos:

\begin{itemize}
    \item \textbf{RFI de banda ancha:} Afecta todo el rango de frecuencias observado (ruido de amplio espectro generado por equipos electrónicos o descargas eléctricas).
    \item \textbf{RFI de banda estrecha:} Limitada a rangos espectrales específicos (emisiones en frecuencias puntuales de transmisores de radio, telecomunicaciones, satélites o señales periódicas terrestres).
\end{itemize}

Un principio fundamental para distinguir RFI de una verdadera señal celestial es la medida de dispersión (DM). Una fuente astrofísica extragaláctica exhibirá un DM elevado ($\gg$0), correspondiente a la columna de electrones en su recorrido, mientras que una emisión terrestre local tendrá DM$\approx$0 (no ha atravesado plasma cósmico). A continuación se resumen varias técnicas populares de excisión de RFI:

\paragraph{Máscara de Canal Estática}

Consiste en ignorar de antemano aquellas frecuencias que se sabe están permanentemente contaminadas por RFI local. Todo radiotelescopio convive con fuentes terrestres persistentes en ciertas bandas, por lo que se elabora una máscara fija de canales frecuenciales que serán eliminados en los datos antes de cualquier análisis. Esta máscara estática previene detecciones espurias en esas bandas inutilizables. Su inconveniente principal es que no se adapta a la variabilidad temporal de la RFI ni a la aparición de nuevas interferencias en frecuencias previamente limpias. Por ello, la máscara debe actualizarse periódicamente si las condiciones de RFI cambian. Actualmente, la mayoría de pipelines complementan (o sustituyen) la máscara estática con métodos más dinámicos.

\paragraph{Filtro de DM = 0 (Zero-DM)}

Este método ataca específicamente la RFI de banda ancha. Se basa en que una señal terrestre afectará por igual a todas las frecuencias instantáneamente (DM 0), mientras que una astrofísica legítima llegará dispersada (DM $>$ 0). El procedimiento es: se dedispersa el espectro dinámico a DM = 0 (alineando las frecuencias como si la señal no estuviera dispersa) y luego se sustrae esa serie temporal de cada canal de frecuencia original. En esencia, se calcula el componente común a todas las frecuencias y se resta para eliminarlo, anulando pulsos amplios no dispersos y suprimiendo gran parte de las interferencias de banda ancha. Esta técnica es sencilla y rápida, y suele incluirse por defecto en muchas búsquedas estándar de FRBs.

No obstante, el filtro de DM=0 conlleva posibles penalizaciones. Si un FRB verdadero tiene señal muy fuerte detectable en todos los canales (S/N alto por canal), al sustraer la media común se puede remover parte de la señal astrofísica junto con la RFI, reduciendo su significancia. Asimismo, si el FRB tuviera un DM intrínsecamente bajo (dentro de nuestra Galaxia), su barrido en frecuencia se parecería a una interferencia de banda ancha y el filtro podría cancelar una fracción sustancial de ese pulso real. Afortunadamente, la mayoría de FRBs extragalácticos exhiben DMs grandes y suelen ser débiles en cada canal individual, por lo que el filtro zero-DM funciona bien en la mayoría de casos.

\paragraph{Umbralizado en Tiempo Real}

En observaciones de alta cadencia temporal, el entorno RFI puede cambiar de un instante a otro. Las máscaras estáticas resultan inadecuadas para lidiar con explosiones breves de interferencia o señales intermitentes. Los algoritmos de umbralizado dinámico operan en tiempo real identificando y eliminando muestras anómalas basadas en estadísticas locales de la señal. En esencia, se calcula la potencia media y desviación estándar en ventanas cortas de datos (bloques de $\sim$1 segundo en cada sub-banda o haz), y se descartan aquellas muestras que excedan cierto umbral de sigma por encima del ruido de fondo. Este procedimiento se puede aplicar tanto en el dominio temporal como frecuencial, e incluso de forma iterativa (varias pasadas) para refinar la limpieza. La clave es que el umbral se recalcula continuamente adaptándose a cambios lentos en la estadística de ruido.

Implementaciones de este tipo han sido empleadas con éxito en experimentos como CHIME/FRB y el radiotelescopio Apertif. Estas técnicas logran atenuar gran parte de las interferencias impulsivas consumiendo apenas el $\sim$1--5\% del presupuesto de cómputo total del pipeline, lo cual es crucial para mantener el procesamiento en línea con la adquisición de datos ($>$100 Gbps en algunos sistemas modernos).

\paragraph{IQRM (Inter-Quartile Range Mitigation)}

IQRM emplea el rango intercuartílico para detectar outliers debidos a RFI en cada canal de frecuencia. El procedimiento es: para un bloque de datos, se calcula algún estadístico robusto (mediana o rango intercuartil) de la señal en cada frecuencia. Suponiendo que la mayoría de canales son limpios, este estadístico caracterizará el nivel base de ruido. Luego, se identifican aquellos canales cuyos valores se desvían significativamente del comportamiento nominal (por encima de un umbral definido en términos de cuartiles o desviaciones robustas). Tales canales anómalos—que típicamente corresponden a interferencia de banda estrecha persistente—se marcan y excluyen del análisis subsiguiente.

IQRM filtra canales corruptos aprovechando que la RFI suele inducir distribuciones no gaussianas con colas fuertes que elevan métricas como la mediana o el rango intercuartil por encima de lo esperable en ruido térmico. Su fortaleza es la capacidad de atrapar RFI variable en el tiempo y de banda relativamente estrecha que otros métodos pasan por alto. Sin embargo, si la mayor parte de un bloque de datos está afectado por RFI, la estimación del estadístico de referencia se contamina y IQRM pierde eficacia. En la práctica, IQRM se usa complementariamente junto con otras técnicas.

\paragraph{Filtro Z-dot}

Este método es una variante mejorada del filtro de DM=0, diseñada para evitar la sobre-sustracción de señal astrofísica en casos donde el pulso real es fuerte. En lugar de restar ciegamente la misma serie de DM=0 a todos los canales, se ajusta cuánto de esa serie sustraer de cada canal individualmente. Por cada canal de frecuencia se determina un factor de escala óptimo (mediante mínimos cuadrados) que modele la interferencia de banda ancha presente en ese canal, y solo se resta esa porción correspondiente de la serie de DM=0. De este modo, si en un canal hay señal astrofísica significativa, el algoritmo tenderá a asignarle un peso menor a la resta, preservando mejor la forma del pulso verdadero. Al ponderar diferencialmente la sustracción por canal, elimina la RFI de banda ancha casi tan efectivamente como el filtro tradicional, pero minimizando la pérdida de señal en canales donde hay un pulso disperso real.

\paragraph{Curtosis Espectral (Spectral Kurtosis)}

La curtosis espectral (SK) examina la forma de la distribución de potencia en cada canal para detectar desviaciones de la gaussianidad esperada del ruido térmico. En ausencia de señal artificial, el ruido del receptor y del cielo tiende a distribuirse de manera aproximadamente normal en cada frecuencia. La presencia de RFI—especialmente si es pulsante o modulada—introduce componentes determinísticas o impulsivas que hacen la distribución más apuntada o con colas más pesadas, alterando la curtosis (cuarto momento estadístico). El estimador calcula un valor de curtosis normalizado que debe ser $\sim$1 para ruido gaussiano ideal. Cuando aparece RFI, este valor se aleja significativamente de 1. La gran ventaja es que SK puede funcionar en tiempo real y de manera independiente por canal, sin necesidad de conocer a priori la forma de la interferencia, detectando señales anómalas sin afectar una señal astrofísica enterrada en ruido gaussiano.

\paragraph{Mitigación RFI Off-line (Secundaria)}

A pesar de todos los filtros aplicados en vivo, es común que tras la detección inicial de un FRB se realice una limpieza secundaria fuera de línea para optimizar la calidad de los datos almacenados. Cuando el pipeline detecta un candidato por encima de cierto umbral, se congela y guarda ese segmento de datos de alta resolución para análisis posterior. Se pueden aplicar técnicas más intensivas que serían demasiado lentas para el pipeline en tiempo real: varias pasadas de filtrado, recalcular estadísticas globales de ruido, identificar outliers más sutiles, y emplear métodos en el dominio de Fourier para suprimir tonos periódicos débiles. Estas limpiezas off-line pueden mejorar la relación señal/ruido final del FRB detectado, recuperando detalles finos de la forma del pulso que estaban ocultos por ruido.

\subsubsection{Fortalezas y Limitaciones de los Pipelines Clásicos: Madurez vs. Escalabilidad y Falsos Positivos}

Las fortalezas de los pipelines clásicos incluyen su madurez, comunidad amplia de usuarios, e integración robusta con formatos astronómicos estándar. Estas herramientas han sido probadas extensivamente en una variedad de proyectos y han demostrado su efectividad para detectar pulsares y transientes en condiciones controladas.

Sin embargo, las limitaciones son significativas: alta tasa de falsos positivos, necesidad de tuning manual extensivo, escalabilidad limitada en grandes DM-planes y datos largos, y contraste reducido en el régimen milimétrico \citep{Barsdell_2012}. La de-dispersión exhaustiva tiene alto costo computacional por redundancias, y un mismo pulso puede generar duplicados a DMs cercanas. Además, incluso tras la filtración inicial, siempre quedan ruidos e interferencias residuales, e incluso pueden introducirse artefactos nuevos durante la propia mitigación de RFI. 

El costo computacional elevado deriva en operaciones ineficientes que producen resultados incompletos y una avalancha de falsos positivos, obligando a una verificación manual intensiva para distinguir las verdaderas señales astrofísicas. En la práctica, proyectos como CHIME/FRB producen grandes volúmenes de candidatos diarios, de los que solo una fracción es real \citep{CHIME2021}. Esta limitación de escalabilidad frente al creciente volumen de datos esperado en radioastronomía ha motivado a la comunidad a desarrollar algoritmos más eficientes y automatizados para futuras búsquedas de FRBs en tiempo real.

\subsubsection{Técnicas de Dedispersión: Desde Fuerza Bruta hasta Algoritmos Optimizados en GPU}

Debido al efecto de la dispersión plasmática, un pulso emitido por un FRB llega a la Tierra con un retardo en las frecuencias bajas respecto a las altas. Este retraso, proporcional a la DM, puede ser de segundos para pulsos extragalácticos en bandas métricas. El proceso de corrección se denomina dedispersión, y es un paso esencial antes de buscar pulsos en los datos. Como no conocemos de antemano la DM del próximo FRB, el pipeline debe dedispersar los datos en múltiples trials que cubran desde DM=0 hasta un DM máximo (p.ej., DM $\sim$ 3000 pc/cm$^3$ para incluir eventos cosmológicos lejanos). Calcular la dedispersión para miles de DM diferentes en tiempo real es uno de los mayores retos computacionales del pipeline.

\paragraph{Dedispersión por Fuerza Bruta}

El método directo sigue la definición: para cada DM trial, desplazar cada canal un número apropiado de muestras y luego sumar todas las frecuencias en cada instante de tiempo. Implementado de forma ingenua, esto implica una complejidad de orden $O(N_t \times N_\nu \times N_{DM})$, donde $N_t$ es el número de muestras en el tiempo, $N_\nu$ el número de canales de frecuencia, y $N_{DM}$ la cantidad de trials de DM.

Afortunadamente, se aplican varias optimizaciones: (1) se reduce la resolución temporal (integrar o decimar muestras) en proporción a la dispersión intra-canal esperada para DMs elevados, sin pérdida sensible de sensibilidad; (2) dedispersión en sub-bandas: se divide la banda en sub-bandas más estrechas que se dedispersan independientemente y luego se combinan los resultados, reduciendo efectivamente $N_\nu$ en cada operación; (3) aprovechamiento de jerarquía de memorias, estructurando los accesos para reutilizar los mismos datos desde caché múltiples veces, minimizando accesos a la RAM principal. Combinando estas optimizaciones, diversos pipelines han logrado implementar dedispersión incoherente en tiempo real aún con decenas de gigabits por segundo de entrada. Por ejemplo, el sistema ARTSA de Apertif alcanzó $\sim$1 petaflops de rendimiento efectivo para dedispersar 45411 trial-DMs en streaming.

\paragraph{Dedispersión mediante Árbol (Tree Dedispersion)}

Para reducir la complejidad algorítmica, se propuso un enfoque divide y vencerás conocido como dedispersión en árbol. En este método, se aprovecha la estructura matemática del corrimiento temporal con la frecuencia para evitar cálculos redundantes. Se reformula la integración a lo largo de la curva de dispersión como una suma de contribuciones lineales, de manera que muchas sumas parciales pueden reutilizarse para múltiples DM cercanos. Esto reduce la complejidad teórica de $\sim O(N_t N_\nu N_{DM})$ a aproximadamente $O(N_t N_\nu \log N_\nu)$, un ahorro sustancial cuando $N_{DM}$ es grande.

El algoritmo en árbol funciona calculando primero dedispersión para un subconjunto reducido de DMs y luego interpolando resultados para DMs intermedios mediante combinaciones lineales de las sumas ya obtenidas. En la práctica, se construye un árbol binario donde en cada nivel se duplica la resolución en DM a costa de combinar resultados de niveles previos. La dedispersión en árbol logra orden de magnitud de mejora en velocidad, y su desempeño práctico es mejor en GPUs u arquitecturas de cómputo masivamente paralelo.

Una variante notable es el \textbf{Fast Dispersion Measure Transform (FDMT)}, que combina complejidad baja tipo árbol y cálculo exacto de la dedispersión cuadrática completa (no linealizada). FDMT reorganiza los datos en una matriz tiempo-retardo y luego aplica transformadas iterativas para acumular la energía dispersa eficientemente. Es especialmente ventajoso con anchos de banda fraccional altos o DMs muy grandes, donde la aproximación lineal del método de árbol podría fallar.

\paragraph{Dedispersión Semicoherente}

La dedispersión coherente consiste en compensar exactamente la rotación de fase inducida por el plasma en la señal de radio, aplicando un filtro de fase antes de formar la intensidad. Es muy costosa computacionalmente para aplicar sobre la marcha a todos los datos. La solución intermedia es la dedispersión semicoherente: se elige una rejilla más gruesa de DMs y para cada una se realiza dedispersión coherente de las señales (corrigiendo fase). Esto alinea perfectamente los pulsos cercanos a esa DM base. Después, se toma la salida de esa corrección coherente y se busca incoherentemente en un rango estrecho de DMs alrededor de la base. De este modo, la mayor parte del ensanchamiento por dispersión se elimina, mejorando la sensibilidad, pero sin el coste exorbitante de hacer coherente cada DM fina. La dedispersión semicoherente ha demostrado recuperar S/N extra en comparativa con la puramente incoherente, sobre todo para pulsos de DM alta.

\paragraph{Dedispersión en el Dominio de Fourier}

Un enfoque alternativo es trasladar el problema al dominio frecuencial. En lugar de desplazar muestras una por una, se multiplica la transformada de Fourier de cada canal por un factor de fase correspondiente al retardo para la DM dada. Luego, sumando las transformadas y aplicando transformada inversa, se obtiene la serie dedispersada. La gran ventaja es que, mediante propiedades de linearidad, la transformada inversa final puede realizarse una sola vez, después de combinar todas las frecuencias. Implementaciones de dedispersión en el dominio de Fourier han mostrado ser eficientes en GPU, resolviendo grandes números de DM trials con menor carga sobre la memoria que el algoritmo temporal tradicional.

\subsubsection{Filtrado por Correlación (Matched Filtering): Maximización de SNR mediante Boxcars y Ventanas Multi-escala}

Incluso tras dedispersar, la detección de un pulso enterrado en ruido requiere una técnica robusta. El filtrado adaptado o \textit{matched filtering} es la herramienta estándar en procesamiento de señales para extraer señales de forma conocida inmersas en ruido gaussiano. Consiste en convolucionar la serie temporal (dedispersada) con una forma de pulso esperada, optimizando así la relación señal/ruido (S/N) de la salida. En el caso de FRBs, que típicamente se manifiestan como pulsos de duración corta (del orden de milisegundos), lo usual es emplear como plantilla una función rectangular (\textit{boxcar}) o aproximaciones gaussianas de distintas anchuras.

En términos simples, el pipeline calcula el S/N que resultaría al integrar la señal en ventanas de diferentes duraciones. Si la ventana coincide con la anchura real del pulso, el S/N alcanzará un máximo. En la práctica, se generan muchas ventanas boxcar de anchuras crecientes (e.g. 1, 2, 4, 8, ..., 256 muestras) y se calculan eficientemente mediante convoluciones o mediante integrales acumulativas rápidas. A medida que aumenta la anchura de integración, se reduce la resolución temporal. Por ello, es común decimar (sub-muestrear) la serie de tiempo dedispersada a resoluciones más gruesas cuando se evalúan ventanas largas, ahorrando cómputo sin pérdida de sensibilidad.

La selección de anchuras a buscar suele hacerse en espaciado geométrico (factores de 2) para cubrir eficazmente varios órdenes de magnitud sin exceso de solapamiento. Típicamente, los FRBs conocidos tienen duraciones entre $\sim$0.1 ms y $\sim$100 ms, por lo que esa es la gama que abarcan la mayoría de pipelines en tiempo real. Sin embargo, recientemente se han descubierto pulsos fuera de este rango, por ejemplo componentes periódicas que se extienden hasta 3 segundos (FRB20191221A), o bursts ultra-cortos de apenas microsegundos de duración. Estos hallazgos evidencian que limitar el filtro a 100 ms podría omitir FRBs anómalos de emisión muy ancha, aunque sean casos raros.

\subsubsection{Clasificación de Candidatos: Reducción de Millones de Eventos a Detecciones Confirmadas}

Después del filtrado, un buscador de FRBs genera potencialmente miles o millones de "candidatos": picos de S/N que superan el umbral definido. La inmensa mayoría de estos candidatos no son verdaderos FRBs, sino artefactos producidos por RFI residual, ruido gaussiano estadístico o pulsos de radiación de origen humano. Por ello, un componente crítico del pipeline es la clasificación y filtrado de candidatos, que busca reducir drásticamente la tasa de falsos positivos, idealmente aislando a unos pocos candidatos prometedores para inspección humana o confirmación automática.

\paragraph{Filtrado Básico y Clustering}

Una vez obtenida la lista bruta de detecciones (tiempo de llegada, DM, anchura y S/N de cada candidato), se aplican cortes sencillos basados en conocimiento físico. Por ejemplo, cualquier candidato con DM por debajo de un cierto umbral (DM $<$ 5--10 pc/cm$^3$) probablemente corresponde a RFI terrestre, así que suele ignorarse. De igual modo, candidatos con anchuras excesivamente grandes ($\gg$100 ms) son probablemente interferencia o variaciones lentas de ganancia. Estas reglas de sifting eliminan una gran fracción de eventos triviales desde el inicio.

A continuación, se procede al agrupamiento (\textit{clustering}) de candidatos duplicados. Un FRB real y brillante puede generar decenas de detecciones redundantes: aparecerá como candidatos en DMs cercanas (porque el pulso sigue siendo visible aunque la dedispersión no sea exactamente la óptima) y en anchuras distintas (un mismo pulso puede sobresalir en varias ventanas de integración). Todos esos candidatos relacionados deben unificarse en uno solo para no sobreestimar la cantidad. Un método común es el algoritmo amigo-de-amigo: se define una distancia métrica en el espacio (tiempo, DM, anchura) y se unen en un mismo clúster todos los candidatos que caen a distancia menor que cierto umbral entre sí. Se selecciona entonces el mejor candidato del grupo (el de mayor S/N) como representativo. El resultado es una lista reducida de clústeres candidatos, normalmente de orden $10^2$--$10^3$ eventos en total (frente a miles o millones iniciales).

\paragraph{Técnicas de Aprendizaje Automático para Clasificación}

A pesar de las etapas anteriores, en un entorno con RFI intensa aún pueden quedar cientos de candidatos por hora que requieren distinguir entre genuinos y espurios. Para reducir la carga de inspección manual, se han incorporado soluciones de inteligencia artificial al pipeline de FRBs. Se han entrenado redes neuronales convolucionales (CNNs) para reconocer las huellas características de un FRB real en contraste con interferencias terrestres o ruido aleatorio.

El enfoque típico consiste en alimentar a la red neuronal con representaciones visuales o matriciales de cada candidato. Suele usarse el espectrograma dedispersado centrado en el tiempo y DM del candidato: un recorte de los datos en torno al evento construyendo una imagen con el eje de frecuencia vs. tiempo, donde un FRB verdadero debería aparecer como una traza bien definida con pendiente (si la dedispersión no fue exacta) o vertical clara (si está correctamente dedispersado). La CNN procesa esas entradas y emite una clasificación o probabilidad de que el candidato sea astrofísico.

La incorporación de machine learning ha permitido automatizar en gran medida la confirmación de detecciones, disminuyendo drásticamente la tasa de falsas alarmas. Esto tiene un impacto directo en la latencia del sistema: si solo unos pocos candidatos superan el filtro final de la red neuronal, el pipeline puede generar alertas más rápido y con mayor confianza. En la actualidad, muchos sondeos de FRBs en curso utilizan CNNs u otros clasificadores (random forests) en tiempo real como paso final antes de declarar una detección. Es importante recalcar que estos modelos deben ser entrenados cuidadosamente y validados para cada nuevo telescopio o configuración, ya que la morfología del ruido y RFI varía.

\subsubsection{Sistema de Buffering, Activación y Alertas: Preservación de Datos Crudos y Coordinación Multi-longitud de Onda}

Detectar un FRB es solo el primer paso; para explotar todo su potencial científico es necesario localizarlo con precisión en el cielo y recopilar la mayor información posible de inmediato. Por ello, los pipelines modernos incorporan mecanismos de buffering, triggering y alertado tras la detección de un candidato de FRB.

La localización exacta (a nivel de unos pocos segundos de arco o mejor) permite identificar la galaxia anfitriona del FRB, midiendo su corrimiento al rojo y, por ende, la distancia precisa. Esto permite estimar cuántos electrones en el medio intergaláctico contribuyeron a la DM medida, dato crucial para estudios cosmológicos como el censo de bariones ocultos. Además, conocer la galaxia y entorno del FRB brinda pistas sobre el posible progenitor (si proviene de una galaxia joven con intensa formación estelar sugiere cierta clase de fuente, versus una galaxia elíptica tranquila que sugiere otra).

Para lograr esta localización, muchos telescopios implementan un \textbf{buffer de voltaje crudo} de alta resolución que está continuamente almacenando en memoria un corto lapso de datos (por ejemplo, 10 segundos más recientes). Cuando el pipeline confirma un FRB, dispara (\textit{trigger}) la conservación de esos datos en disco. Así se preserva la señal tal cual fue recibida, antes de promedios o dedispersión, lo que permite posteriormente realizar análisis mucho más detallados. Con los voltajes se puede formar una imagen interferométrica del cielo en el instante del FRB (en telescopios con múltiples antenas), obteniendo una posición precisa del evento. También se pueden dedispersar coherentemente y re-muestrear a resoluciones de microsegundos para estudiar la estructura temporal fina del pulso.

Dado que almacenar voltajes supone volúmenes enormes de datos, el buffer suele ser corto y se limita a guardar solo un segmento alrededor del tiempo del FRB (1 segundo antes y después del evento). Si la latencia del pipeline es baja (unos pocos segundos), esto es suficiente para capturar el pulso completo una vez detectado. De ahí la importancia de la eficiencia en todas las etapas.

En paralelo al guardado de datos, el pipeline emite una \textbf{alerta pública} siguiendo protocolos estándar (generalmente formato VOEvent para transientes rápidos). Esta alerta contiene la hora de detección, DM, estimación de posición, anchura, fluencia, etc. Observatorios alrededor del mundo, de rayos X, óptico, infrarrojo, pueden entonces repuntar sus instrumentos hacia la zona y tratar de captar radiación de alta energía, brillo óptico transitorio u otras contrapartes asociadas al FRB. Adicionalmente, si el propio radiotelescopio es un arreglo, a partir de los datos en buffer se pueden recalcular las trazas de diferencia de tiempo de arribo entre antenas y así deducir la posición con resolución sub-arco.

En suma, el pipeline no termina en "encontré un FRB", sino que activa una serie de acciones para maximizar el retorno científico: guarda los datos crudos para análisis pormenorizado y alerta a la comunidad para obtener datos complementarios.


\subsection{Machine Learning en Radioastronomía: De la Clasificación Post-hoc a la Detección Integrada}

\subsubsection{Motivación y Evolución: De Pipelines GPU-Acelerados a Detectores Directos con Deep Learning}

En los últimos años se han desarrollado pipelines de nueva generación con mejoras en velocidad y reducción de falsos positivos, incorporando procesamiento acelerado en GPU (e.g., FREDDA en ASKAP/MeerKAT) y etapas automáticas de clasificación basadas en machine learning. Inicialmente, las redes neuronales se aplicaron a la \textit{clasificación} de candidatos generados por métodos clásicos (p.ej., FETCH) reduciendo la inspección manual \citep{Agarwal_2020,Petroff_2022}. Si bien estos clasificadores disminuyen los falsos positivos y mejoran la eficiencia de la búsqueda, no abordan otros problemas fundamentales de los métodos tradicionales, en particular la incompletitud de detección (es decir, la posibilidad de que algunos FRBs débiles ni siquiera lleguen a ser candidatos).

Más allá de la post-clasificación, algunos investigadores han intentado aplicar deep learning para detectar directamente las firmas de FRB en los datos crudos, usando CNNs para buscar las típicas trazas parabólicas de un FRB en visualizaciones tiempo-frecuencia sin etapa previa de dedispersión exhaustiva \citep{Zhang_2020}. Sin embargo, estos enfoques enfrentan obstáculos significativos: (1) los pulsos muy débiles y dispersos pueden quedar ocultos en las imágenes dinámicas, haciendo que la red pase por alto FRBs de baja intensidad; (2) la curvatura de la "parábola" varía con la DM de cada FRB, dificultando decidir un tamaño fijo de ventana de entrada; (3) estos detectores directos suelen identificar solo el tiempo de llegada del pulso, pero no proporcionan la DM, requiriendo pasos adicionales de análisis para caracterizar completamente el evento.

Las imágenes tiempo–frecuencia y tiempo–DM sirven como representaciones fundamentales para algoritmos de machine learning. Estas representaciones requieren normalización robusta, enmascarado de RFI, y data augmentation para mejorar la generalización. El transfer learning y la calibración de probabilidades son técnicas críticas para adaptar modelos entrenados en un telescopio a datos de otros instrumentos \citep{Agarwal_2020}.

\subsubsection{FETCH: Clasificador de Candidatos mediante CNN de Doble Rama para Reducción de Inspección Manual}

FETCH (Fast Transient Classification) representa un clasificador de candidatos basado en deep learning que utiliza una arquitectura de doble rama CNN \citep{Agarwal_2020}. El sistema procesa tanto representaciones tiempo-frecuencia (TF) como tiempo-DM, fusionando las características extraídas mediante softmax para clasificar candidatos como FRBs genuinos o RFI.

Las ventajas de FETCH incluyen la reducción significativa de inspección manual y la capacidad de aprender patrones complejos en los datos. Sin embargo, las limitaciones son importantes: dependencia del patrón bow-tie, degradación del rendimiento con S/N bajo, y dificultades de transferencia entre dominios (diferentes telescopios o condiciones observacionales) \citep{Agarwal_2020}.

\subsubsection{DRAFTS: Detección + Clasificación Integrada mediante CenterNet y Dedispersión CUDA}

El estado del arte lo representa \textbf{DRAFTS} (\textit{Deep-learning RAdio Fast Transient Search}) \citep{zhang2024drafts}: un pipeline integral de \textit{deep learning} que integra detección y clasificación de forma unificada. DRAFTS combina lo mejor de ambos mundos: aprovecha la física de dispersión mediante dedispersión acelerada en GPU y a la vez incorpora modelos de visión por computador para identificar y verificar los pulsos de FRB en los datos de radio. Su objetivo es mejorar eficiencia, completitud y velocidad, reduciendo falsos positivos frente a enfoques clásicos.

\paragraph{Arquitectura de DRAFTS}

DRAFTS consta de tres componentes principales que operan de forma secuencial:

\begin{enumerate}
    \item \textbf{Dedispersión CUDA:} Realiza la corrección por dispersión de manera altamente paralelizada, explorando rápidamente un rango de DM en la dinámica de frecuencias y tiempos. Esta etapa genera una representación 2D (tiempo en $x$, DM en $y$) donde un FRB aparece como región compacta con firma de \textit{bow-tie}.
    
    \item \textbf{Detección por aprendizaje profundo:} Emplea un detector \textit{anchor-free} (\textbf{CenterNet}) \citep{Zhou_2019_CenterNet} que recibe como entrada las representaciones tiempo-DM de los datos dedispersados. Al enfocarse en los puntos centrales de cada señal, CenterNet evita la complejidad de manejar múltiples cajas predeterminadas y mejora la sensibilidad a señales débiles o de tamaño variable. La red, con backbone tipo \textbf{ResNet} \citep{He_2015_ResNet}, infiere directamente el tiempo de llegada y la DM óptima del pulso, localizando las "huellas" de los FRBs en el espacio tiempo-DM.
    
    \item \textbf{Clasificación binaria:} Una vez marcada una detección, se extrae la subtrama correspondiente, se de-dispersa a su DM óptima y se pasa a una red de clasificación (ResNet) que determina si la señal detectada corresponde a un FRB real o a un falso positivo. Esta red está entrenada con bursts reales y casos negativos de RFI/ruido \citep{Agarwal_2020,zhang2024drafts}. Esta etapa final asegura una precisión $>$99\% al validar eventos en datos reales, reduciendo drásticamente la necesidad de verificación humana.
\end{enumerate}

\paragraph{Rendimiento y Validación}

Gracias a esta arquitectura híbrida, DRAFTS ha demostrado desempeños superiores frente a los pipelines tradicionales. En datos reales del radiotelescopio FAST y GBT, DRAFTS logró:

\begin{itemize}
    \item \textbf{Operación en tiempo real:} Capaz de procesar datos sobre hardware gráfico de consumo (GPU RTX 2070 Super), cumpliendo las exigencias de velocidad para futuros sondeos de gran volumen.
    \item \textbf{Mayor completitud:} En pruebas con datos del repetidor FRB 20190520B, DRAFTS detectó más del triple de ráfagas en comparación con Heimdall bajo las mismas condiciones, rescatando pulsos que las técnicas tradicionales pasaron por alto.
    \item \textbf{Alta precisión:} Globalmente supera a los métodos clásicos en rapidez, exactitud y tasa de verdaderos positivos, casi duplicando la tasa de detección de ráfagas sin inundar de señales espurias.
    \item \textbf{Eficiencia computacional:} Evita cómputos redundantes sobre DMs similares, minimiza duplicados y aprende variabilidad morfológica relevante manteniendo bajo falso positivo \citep{zhang2024drafts,Heimdall_Use}.
\end{itemize}

\paragraph{Limitaciones Identificadas}

No obstante, DRAFTS presenta limitaciones y "puntos ciegos" importantes:

\begin{itemize}
    \item \textbf{Sensibilidad a señales débiles:} Los FRBs más débiles—aquellos prácticamente imperceptibles a simple vista en los diagramas dispersión-tiempo—pueden escaparse del detector de objetos. En pruebas, algunas ráfagas muy tenues fueron detectadas solo en la etapa de clasificación (por su firma en la serie temporal) pero pasaron inadvertidas en la etapa de localización automática.
    \item \textbf{Optimización de representaciones:} Existe margen para mejorar la conversión de datos tiempo-frecuencia a representaciones tiempo-DM con mejor relación señal/ruido, o refinando los modelos para resaltar trazas débiles.
    \item \textbf{Adaptación instrumental:} DRAFTS fue entrenado y validado con datos de telescopios operando en bandas de radio convencionales (FAST a $\sim$1.4 GHz, GBT en bandas de centímetros). Su adaptación a otros entornos espectrales o instrumentales—por ejemplo, búsquedas en frecuencias más altas—podría requerir re-entrenamiento con distintos patrones de ruido e interferencia.
\end{itemize}

Este balance entre éxito demostrado y limitaciones identificadas motiva el desarrollo de DRAFTS++, abordado en las secciones posteriores.

\subsection{El Desafío de Alta Frecuencia (mm-wave): Compresión Dispersiva y Nuevas Estrategias de Detección}

\subsubsection{Compresión Dispersiva en mm-wave: Supresión del Patrón Bow-Tie y Pérdida de Contraste}

A frecuencias de decenas a centenas de GHz, $\Delta t\propto \nu^{-2}$ reduce el contraste dispersivo en banda; la señal aparece casi simultánea en frecuencia, dificultando discriminación frente a ruido/RFI \citep{LorimerKramer2004,CordesChatterjee2019}. Esta "compresión dispersiva" significa que el patrón bow-tie característico se aplana, eliminando el principal discriminador visual entre señales astrofísicas genuinas e interferencia de radiofrecuencia.

La supresión de dispersión en el régimen milimétrico tiene implicancias fundamentales para las estrategias de detección. El criterio DM deja de ser tan discriminante, y los métodos tradicionales basados en la firma dispersiva pierden efectividad. Esto requiere el desarrollo de estrategias alternativas que no dependan del patrón bow-tie para la detección inicial \citep{veracasanova2025}.

\subsubsection{Requisitos Técnicos para Detección en mm-wave: Resolución, Ancho de Banda y Sensibilidad}

Los requisitos instrumentales para detección en alta frecuencia incluyen resolución temporal y ancho de banda críticos. La sensibilidad instrumental y la tasa de datos exigen procesamiento de baja latencia, mientras que las consecuencias para S/N y selección del plan DM requieren ajustes significativos en los parámetros de búsqueda \citep{veracasanova2025}.

Las evidencias de pulsos de magnetar en mm que motivan el régimen incluyen las detecciones del magnetar del Centro Galáctico con ALMA en modo phased, demostrando viabilidad de detectar transientes a $\sim$100\,GHz \citep{veracasanova2025}. Esto abre la puerta a búsquedas de FRBs repetidores en mm, estableciendo precedentes importantes para el desarrollo de detectores especializados.

\subsubsection{Lagunas en la Literatura: Ausencia de Detecciones Confirmadas de FRBs Extragalácticos por Encima de 10 GHz}

A pesar del progreso en pipelines de FRBs, existe un vacío significativo en la literatura cuando consideramos búsquedas a radiofrecuencias más altas (por encima de las típicas bandas centimétricas). Hasta la fecha, la gran mayoría de FRBs se han detectado en frecuencias entre $\sim$0.4 y 1.7 GHz, con apenas algunas excepciones llegando a la banda C ($\sim$4--8 GHz) en fuentes repetidoras extraordinariamente activas \citep{Gajjar2018,Bethapudi2023}. Por encima de $\sim$10 GHz (ondas milimétricas), no se ha confirmado ningún FRB extragaláctico antes de 2025.

Esta falta de resultados no implica que los FRBs no emitan a frecuencias altas, sino que responde en parte a desafíos tecnológicos y metodológicos: las señales en mm-wave son intrínsecamente más débiles debido a los espectros típicamente decrecientes de las fuentes de radio, lo que exige telescopios extremadamente sensibles. Por otro lado, observar a frecuencias mayores puede mitigar ciertos problemas de propagación: en entornos densos (como el centro galáctico o las regiones circundantes a posibles fuentes de FRB), el scattering y la dispersión temporal inducida por el plasma hacen casi imposible detectar pulsos a 1 GHz, mientras que en bandas milimétricas esos efectos se reducen drásticamente.

Explorar el "territorio inexplorado" de las altas frecuencias podría revelar FRBs que hoy permanecen ocultos por el scattering y la dispersión a bajas frecuencias. Los estudios piloto más recientes—por ejemplo, la detección de pulsos de un magnetar galáctico a $\sim$86 GHz con ALMA \citep{veracasanova2025}—sugieren que instrumentos como ALMA pueden abrir una nueva ventana, pero son necesarios software y algoritmos especializados para explotar plenamente esa oportunidad. Antes de 2025 no se habían realizado búsquedas con ALMA en modo faseado para intentar detectar FRBs extragalácticos, evidenciando esta laguna crítica en el estado del arte.

\subsubsection{Estrategias de Adaptación a Alta Frecuencia: Polarización, Multi-banda y Re-entrenamiento con Datos mm}

Las estrategias de adaptación para alta frecuencia incluyen ampliar el rango y paso de DM, desarrollar features alternativos como polarización (muchos transientes presentan polarización fuerte a altas frecuencias que podría distinguirse del ruido), coincidencias multi-banda, y periodic gating. El re-entrenamiento con datos/simulaciones mm y la integración con ALMA Phased son componentes críticos para el éxito en este régimen \citep{veracasanova2025}.

Las particularidades del régimen mm-wave requieren manejar anchos de banda mucho mayores y diferentes características de RFI (en mm-wave suele haber menos interferencia humana, pero la instrumentación y el ambiente pueden introducir ruido distinto). Los pulsos podrían aparecer con menor S/N debido a la pendiente espectral negativa de la emisión de la mayoría de púlsares y FRBs, requiriendo optimizaciones en la formación de las imágenes dispersas (tiempo vs DM) para realzar mejor cualquier traza sutil en los datos.

Aumentar cobertura (DM/anchos/sub-bandas) incrementa fuertemente el costo; se requieren estrategias focalizadas y aceleración eficiente \citep{zhang2024drafts,Zackay_2014_FDMT}. La RFI y su variabilidad entre instrumentos exigen estrategias dinámicas (p.ej., IQRM, morfología TF, SK) y robustez de dominio \citep{Morello_2021_IQRM,Offringa2010,Offringa2012}.

\subsection{Técnicas Avanzadas y Perspectivas Futuras: Transformadas, Computación Cuántica y la Era de SKA/ngVLA}

\subsubsection{Expansión del Espacio de Parámetros de Búsqueda: Eliminando Sesgos hacia FRBs de 3 Segundos y 30 Microsegundos}

Hasta hace poco se asumía que los FRBs eran pulsos relativamente cortos ($<$ 1 s). Los algoritmos de búsqueda reflejaban este sesgo al limitar, por eficiencia, el rango de anchuras a evaluar (hasta $\sim$100 ms). No obstante, el hallazgo de FRB20191221A, un evento con componentes periódicas que se extienden por 3 segundos en total, obligó a replantear esta suposición. Un análisis mostró que si tal burst de 3 s se hubiese buscado con ventanas máximas de 100 ms, se habría perdido más del 40\% de su energía. Por el otro extremo, recientemente se han detectado micro-bursts de duración del orden de 30 microsegundos provenientes de FRB20121102A. Estas ráfagas ultra-cortas prácticamente se promedian en datos con resolución típica de decenas de microsegundos, escapando de la detección si no se observa a resoluciones más finas.

Ambos descubrimientos evidencian un sesgo observacional: habíamos estado "ciegos" a FRBs muy anchos y muy estrechos por las limitaciones de nuestros pipelines y setups de búsqueda. De cara a SKA y similares, será fundamental eliminar estos sesgos. Esto implica: ampliar el conjunto de anchos de filtro evaluados (quizá dedicando más cómputo a ventanas de hasta varios segundos), mejorar la estabilidad de base de los sistemas para permitir integraciones largas sin derivar a falsos, y explorar configuraciones de alta resolución para captar pulsos sub-milisegundo.

\subsubsection{Transformadas de Radon y Hough: Detección de Trayectorias Dispersivas en Espacio Transformado}

Una dirección prometedora para mejorar la sensibilidad (especialmente a FRBs lejanos y débiles) es replantear el problema de la dedispersión como una búsqueda de trayectorias lineales en un espacio transformado. Las transformadas integrales como la transformada de Radon o la transformada de Hough están diseñadas para detectar líneas o curvas en una imagen.

Al hacer un cambio de variable de $(t, \nu)$ a $(t, \nu^{-2})$, una curva de dispersión (retardo $\propto 1/\nu^2$) se convierte en una línea recta en el plano $t$ vs $\nu^{-2}$. La transformada de Radon proyecta la intensidad a lo largo de líneas en este espacio transformado, por distintos ángulos que corresponderían a diferentes DMs. Un FRB se manifestaría como un pico intenso en la proyección para el ángulo correcto (el que iguala su DM), mientras que el ruido y RFI no coherente se distribuye más homogéneamente. De esta manera, el problema de detección se reduce a encontrar máximos en el espacio Radon, que es más robusto frente a RFI no ajustada a la ley de dispersión.

Ya se han realizado pruebas conceptuales de búsqueda de FRBs usando transformadas de Radon/Hough, con resultados alentadores. El desafío está en la implementación eficiente: hay que remuestrear o interpolar el espectro dinámico a la escala $\nu^{-2}$, y luego calcular las proyecciones para un rango continuo de ángulos (DMs). Una vez obtenido el sinograma (espacio de ángulo vs retardo), la detección de picos puede incluso delegarse a una red neuronal. En suma, la búsqueda transformacional ofrece una vía diferente y potencialmente más inmune a interferencias para encontrar FRBs muy débiles. Es posible que los telescopios de próxima generación incorporen módulos de detección vía Radon/Hough en paralelo a las técnicas tradicionales, aumentando la tasa de descubrimiento especialmente en régimen de baja S/N.

\subsubsection{Búsquedas mediante Computación Cuántica: Paralelismo Masivo y Promesas para la Década de 2040}

Aunque su aplicación práctica aún está en el horizonte, vale la pena mencionar el potencial de la computación cuántica en las búsquedas de FRBs, dada la naturaleza altamente paralela de este problema. Dos características hacen soñar con algoritmos cuánticos:

\begin{enumerate}
    \item \textbf{Paralelismo masivo inherente:} Un pipeline examina simultáneamente cientos de haces del telescopio, miles de DMs y decenas de anchuras de filtro. Esto resulta en millones de operaciones similares aplicadas a los datos. Un algoritmo cuántico podría, en teoría, codificar todas esas combinaciones en estados entrelazados y efectuar la operación equivalente en un solo paso cuántico, aprovechando la superposición. En lugar de dedispersar secuencialmente 10,000 DMs diferentes, un computador cuántico podría preparar un registro cuántico que represente todas las DMs a la vez y aplicar una transformación única que evalúe la presencia o ausencia de un pulso en cualquier DM en ese registro.
    
    \item \textbf{Decisión binaria final:} Al final del pipeline, el resultado se reduce a "¿hay un FRB presente o no?" en el periodo analizado. Esta pregunta sí/no es adecuada para un sistema cuántico, pues tras las operaciones paralelas, un único colapso de la función de onda podría darnos la respuesta binaria. En principio, el sistema cuántico podría detectar la huella del FRB y colapsar a un estado marcado si la encuentra, todo en una fracción del tiempo que un sistema clásico tardaría en computar todas las convoluciones.
\end{enumerate}

Los obstáculos para un uso real en FRBs son considerables: se requeriría convertir los datos de entrada en qubits de manera rápida, diseñar algoritmos cuánticos específicos que incorporen las transformaciones de dispersión, filtrado y clasificación, y escalar a miles o millones de qubits con suficiente estabilidad (bajo ruido cuántico) para procesar los enormes datasets de un SKA. Según estimaciones optimistas, tal escala de hardware podría tardar décadas en estar disponible—quizá hacia la década de 2040 o más allá. Sin embargo, la promesa está ahí: de lograrse, un pipeline cuántico podría, en teoría, reemplazar billones de operaciones clásicas por unas pocas operaciones cuánticas, revolucionando por completo el procesamiento de transientes.

\subsubsection{FRBs en la Era de SKAO y ngVLA: Desafíos de Big Data con Terabits/Segundo y Miles de Detecciones Esperadas}

Los próximos años verán la entrada en operación de nuevos radiotelescopios de gran envergadura que revolucionarán la radioastronomía: el Square Kilometre Array (SKA), el Next-Generation Very Large Array (ngVLA), el Deep Synoptic Array 2000 (DSA-2000), CHORD en Canadá, entre otros. Estas instalaciones ofrecerán órdenes de magnitud más sensibilidad y campo de visión, lo que se traducirá en cantidades de datos colosales a procesar (varios terabits por segundo continuamente). Detectar y localizar FRBs en tales flujos será un desafío de big data sin precedentes.

A la par, se ha hecho evidente que el espacio de parámetros de los FRBs podría ser más amplio de lo asumido. Las tuberías actuales han estado optimizadas para pulsos de hasta decenas de milisegundos y DMs moderadas, basadas en la población inicialmente descubierta. Sin embargo, descubrimientos recientes sugieren que existen FRBs mucho más anchos (en duración) e incluso mucho más breves que los típicos, los cuales podrían estar quedando fuera de las búsquedas estándar. Esto indica que debemos expandir las búsquedas más allá de la "caja" tradicional de parámetros, ajustando o rediseñando los pipelines para no sesgar los resultados.

Con miles de FRBs esperados una vez operen SKA y otros proyectos, estaremos en posición de mapear la distribución de materia en el universo, estudiar campos magnéticos cosmológicos, comprender la física extrema de sus fuentes (posiblemente magnetares jóvenes u objetos exóticos), y quizás descubrir nuevas clases de fenómenos transitorios. Para mantenerse al día con la creciente escala de datos de telescopios de próxima generación, se requieren algoritmos de búsqueda más rápidos y eficientes, capaces de manejar mayores tasas de entrada. En los años venideros, veremos converger enfoques tradicionales y de vanguardia: herramientas de machine learning sofisticadas integradas en los pipelines, nuevas técnicas de filtrado basadas en transformaciones matemáticas, e incluso los primeros atisbos de soluciones cuánticas o híbridas.

\subsection{Estándares de Datos y Metadatos: PSRFITS, Filterbank y Requisitos de Trazabilidad Temporal}

\subsubsection{Formatos Astronómicos: FITS, PSRFITS y SIGPROC Filterbank}

Los formatos astronómicos estándar incluyen FITS (Flexible Image Transport System) con HDUs, tablas, convenciones de encabezado y WCS (World Coordinate System) \citep{Hotan_2004_PSRFITS}. PSRFITS proporciona modos SEARCH vs FOLD, manejo de polarización y compatibilidad con PSRCHIVE, siendo el formato estándar para datos de pulsares y transientes.

SIGPROC Filterbank constituye el formato estándar para espectros dinámicos binarios, proporcionando compatibilidad amplia con herramientas de análisis de radioastronomía. La integración robusta con estos formatos es esencial para el funcionamiento de pipelines modernos \citep{Hotan_2004_PSRFITS}.

\subsubsection{Metadatos Críticos: MJD, Tiempos Absolutos y Sincronización Multi-instrumento}

Los metadatos críticos incluyen MJD (Modified Julian Date) y tiempos absolutos, campos de cabecera esenciales para pipelines que requieren trazabilidad temporal precisa. La calibración de tiempos y la sincronización entre diferentes instrumentos dependen de estos metadatos para garantizar la coherencia científica de los resultados \citep{Hotan_2004_PSRFITS}.

\subsection{Síntesis: Motivación y Justificación de DRAFTS++}

El análisis de este marco conceptual revela dos necesidades críticas que motivan el desarrollo de DRAFTS++:

\paragraph{Llenar las Lagunas en Alta Frecuencia}

La ausencia de pipelines consolidados y experiencias extensivas de búsqueda de FRBs en el régimen milimétrico (decenas de GHz) representa una oportunidad científica significativa. DRAFTS++ se propone extender las capacidades de pipelines basados en deep learning al régimen de frecuencias milimétricas, adaptando la estrategia de detección a las particularidades de estos datos. Esto permitirá explotar plenamente el potencial de instrumentos como ALMA en modo phased para la detección de transientes, abriendo una ventana observacional previamente inexplorada.

\paragraph{Superar los Puntos Ciegos de DRAFTS}

Las limitaciones identificadas en DRAFTS—particularmente la sensibilidad reducida a señales débiles y la necesidad de adaptación instrumental—requieren mejoras específicas. DRAFTS++ incorporará optimizaciones en el preprocesamiento y la detección para fortalecer la capacidad de identificar eventos al límite de la detectabilidad. Además, la evaluación sistemática del desempeño en diferentes regímenes de frecuencia permitirá desarrollar estrategias robustas de transferencia de dominio.

\paragraph{Integración de Mejoras Metodológicas}

DRAFTS++ no solo extiende DRAFTS a nuevos regímenes, sino que integra mejoras metodológicas fundamentales: (1) optimizaciones en la formación de representaciones tiempo-DM para realzar trazas sutiles, (2) incorporación de información auxiliar como polarización cuando esté disponible, (3) estrategias de gestión de memoria y streaming para procesar observaciones de larga duración, y (4) métricas y logging estructurado para validación científica rigurosa.

En síntesis, DRAFTS++ emerge de la convergencia entre oportunidades científicas (el territorio inexplorado de mm-wave), limitaciones técnicas identificadas (sensibilidad a señales débiles), y necesidades operativas (procesamiento robusto de grandes volúmenes de datos). El marco conceptual establecido en este capítulo proporciona los fundamentos científicos, técnicos y metodológicos que justifican cada decisión arquitectónica de DRAFTS++, asegurando que el pipeline resultante no solo funcione técnicamente, sino que responda a necesidades astrofísicas reales y contribuya al avance del campo.

\subsection{Implicancias para el Diseño de DRAFTS++: Principios, Productos y Plan de Validación}

\subsubsection{Principios Arquitectónicos: Modularidad, GPU-First y Chunking Eficiente con Baja Latencia}

Los principios arquitectónicos que emergen de este marco incluyen modularidad, procesamiento GPU-first, chunking eficiente, logging estructurado, y latencia baja. La adaptabilidad a diferentes regímenes de frecuencia requiere un diseño flexible que pueda seleccionar automáticamente la estrategia apropiada según las características observacionales \citep{zhang2024drafts}.

\subsubsection{Conjunto Mínimo de Productos: Detectores, Clasificadores y Métricas de Rendimiento Estandarizadas}

El conjunto mínimo de productos incluye detectores por banda, clasificadores calibrados, validación cruzada multi-telescopio, y métricas de rendimiento (recall@FPR, latencia/GB, costo computacional). Estos productos deben ser estandarizados y reproducibles para facilitar la comparación y validación científica \citep{zhang2024drafts}.

\subsubsection{Plan de Datos y Evaluación: Integración de Datos Simulados y Reales para Validación Científica}

El plan de datos y evaluación requiere un conjunto de entrenamiento (sim+real) para alta frecuencia, criterios de evaluación robustos, y estrategias de validación científica. La integración de datos simulados y reales es esencial para desarrollar algoritmos que funcionen efectivamente en condiciones observacionales reales \citep{zhang2024drafts}.

