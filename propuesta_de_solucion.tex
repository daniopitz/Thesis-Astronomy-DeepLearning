\secnumbersection{Metodología y Diseño del Pipeline}
\setcounter{secnumdepth}{4}
\setcounter{tocdepth}{4}
\makeatletter
\renewcommand\paragraph{\@startsection{paragraph}{4}{\z@}%
  {1.5ex \@plus .5ex \@minus .2ex}%   % espacio antes
  {0.8ex \@plus .2ex}%                 % espacio después
  {\normalfont\normalsize\bfseries}}  % estilo
\makeatother


\subsection{Descripción general}

\textbf{DRAFTS++} es el pipeline de ingeniería de software (Componente 1) que orquesta dos modos de detección complementarios: (a) el \textbf{modo DRAFTS-clásico} para frecuencias bajas (LF, 0.3--8 GHz), que utiliza detección mediante CenterNet pre-entrenado en mapas tiempo--DM seguida de clasificación con ResNet18; y (b) el \textbf{modo HF-PoL} (High-Frequency Polarization-Linear) para frecuencias milimétricas (HF, 30--100 GHz), que combina matched filtering temporal con clasificación dual CNN en intensidad y polarización lineal mediante ResNet18 pre-entrenado. El sistema selecciona automáticamente el modo de detección según el régimen frecuencial observado mediante criterio físico basado en la resolubilidad del retardo dispersivo.

El \textbf{Componente 1} desarrolla la infraestructura de software (pipeline productivo end-to-end con ingesta multi-formato, \textit{streaming} eficiente y orquestación automatizada de modelos) que constituye el habilitador técnico necesario para materializar las estrategias metodológicas en un sistema operativo robusto y reproducible. El \textbf{Componente 2} extiende el sistema al régimen milimétrico mediante el modo HF-PoL, que constituye la contribución metodológica novedosa de mayor impacto científico al abordar el gap crítico de detección en alta frecuencia donde la firma dispersiva tradicional se comprime hasta volverse imperceptible. Ambos componentes operan dentro de la arquitectura unificada de DRAFTS++, garantizando consistencia, reproducibilidad y trazabilidad en todos los regímenes frecuenciales.

\begin{figure}[H]
\centering
\resizebox{0.7\textwidth}{!}{%
\begin{tikzpicture}[
    node distance=0.8cm and 1.2cm,
    box/.style={rectangle, draw, fill=blue!20, text width=2.2cm, text centered, minimum height=0.7cm, font=\tiny},
    decision/.style={diamond, draw, fill=yellow!20, text width=1.8cm, text centered, minimum height=0.7cm, font=\tiny},
    process/.style={rectangle, draw, fill=green!20, text width=2.2cm, text centered, minimum height=0.7cm, font=\tiny},
    output/.style={rectangle, draw, fill=orange!20, text width=2.2cm, text centered, minimum height=0.7cm, font=\tiny},
    arrow/.style={-Stealth, thick}
]

% INICIALIZACIÓN
\node[box] (A) {main.py};
\node[box, below=of A] (B) {Cargar Modelos};

% ENTRADA DE DATOS
\node[box, right=of A] (C) {find\_data\_files};
\node[decision, below=of C] (D) {Tipo\\Archivo?};
\node[box, below left=of D] (E) {fits\_handler};
\node[box, below right=of D] (F) {filterbank\_handler};

% PROCESAMIENTO
\node[box, below=of D] (G) {streaming\_orchestrator};
\node[box, below=of G] (H) {Procesar chunk};
\node[decision, below=of H] (I) {$\Delta t_{\mathrm{ms}} > \alpha t_{\mathrm{samp}}$?};

% PIPELINES
\node[box, below left=of I] (J) {Pipeline\\Alta Frecuencia\\(SNR-threshold)};
\node[box, below right=of I] (K) {Pipeline\\Clásico\\(CenterNet)};

% CLASIFICACIÓN Y VALIDACIÓN
\node[process, below=of J] (L) {Clasificación\\ResNet18};
\node[process, below=of K] (M) {Clasificación\\ResNet18};
\node[process, below=of L] (N) {Validación\\Física};
\node[process, below=of M] (O) {Validación\\Física};

% RESULTADOS
\node[output, below=of N] (P) {Artefactos\\Estandarizados};
\node[output, below=of O] (Q) {Artefactos\\Estandarizados};

% Conexiones principales
\draw[arrow] (A) -- (B);
\draw[arrow] (A) -- (C);
\draw[arrow] (C) -- (D);
\draw[arrow] (D) -- node[left, font=\tiny] {FITS} (E);
\draw[arrow] (D) -- node[right, font=\tiny] {Filterbank} (F);
\draw[arrow] (E) -- (G);
\draw[arrow] (F) -- (G);
\draw[arrow] (G) -- (H);
\draw[arrow] (H) -- (I);
\draw[arrow] (I) -- node[left, font=\tiny] {No} (J);
\draw[arrow] (I) -- node[right, font=\tiny] {Sí} (K);
\draw[arrow] (J) -- (L);
\draw[arrow] (K) -- (M);
\draw[arrow] (L) -- (N);
\draw[arrow] (M) -- (O);
\draw[arrow] (N) -- (P);
\draw[arrow] (O) -- (Q);

\end{tikzpicture}}
\caption[Arquitectura unificada DRAFTS++: Orquestación de modos de detección]{Figura~\ref{fig:pipeline-end-to-end}. Arquitectura unificada de DRAFTS++ orquestando dos modos de detección. Flujo principal: ingesta automática $\to$ streaming con gestión de memoria $\to$ selección de modo según régimen frecuencial (criterio $\Delta t_{\mathrm{ms}} \le \alpha\, t_{\mathrm{samp}}$). Modo LF (DRAFTS-clásico): CenterNet propone candidatos (DM, t) $\to$ ResNet18 clasifica. Modo HF (HF-PoL): matched filtering temporal $\to$ clasificación dual ResNet18 (I+L). La arquitectura garantiza consistencia y reproducibilidad en todos los regímenes frecuenciales.}
\label{fig:pipeline-end-to-end}
\end{figure}

\subsection{Contexto de implementación} 

El sistema se implementó en Python 3.9, utilizando PyTorch/torchvision para la inferencia de los modelos, y Astropy/NumPy para manejo de archivos FITS/PSRFITS y procesamiento numérico. El código fuente y la documentación técnica se encuentran disponibles públicamente en el repositorio de GitHub\footnote{\href{https://github.com/Kodamonkey/DRAFTS-UC}{https://github.com/Kodamonkey/DRAFTS-UC}}.

\subsection{Componente 1: Infraestructura de Software}

Este componente aborda la transición de DRAFTS, concebido originalmente como un prototipo de investigación, hacia un sistema \textbf{productivo y operativo} capaz de funcionar en entornos observacionales reales. Esta transición requiere una reformulación arquitectónica profunda, orientada a superar las limitaciones del código base original y a garantizar la escalabilidad, robustez y reproducibilidad necesarias para su integración en flujos astronómicos de detección de transientes. Este componente constituye el \textbf{habilitador técnico} necesario para materializar las estrategias metodológicas del Componente 2 en un sistema operativo robusto y reproducible, proporcionando la infraestructura de software que permite la extensión a alta frecuencia.

\subsubsection{Arquitectura modular y escalable: DRAFTS++}

\textbf{DRAFTS++} se estructura como un \textit{pipeline} modular y escalable que ofrece un punto de entrada unificado mediante interfaz de línea de comandos (CLI), con configuración versionada y orquestación automática de las etapas de ingesta, preprocesamiento, detección y clasificación. El sistema se organiza en módulos independientes (lectura de datos, dedispersión, inferencia, validación, visualización) con interfaces bien definidas y contratos formales entre etapas, facilitando el mantenimiento, la extensibilidad y la evolución independiente de cada componente. Esta arquitectura incorpora servicios transversales (\texttt{core/}, \texttt{config/}, \texttt{logging/}, \texttt{scripts/}) que proporcionan orquestación centralizada, validación de configuraciones, trazabilidad completa mediante \textit{logging} estructurado, y garantías de reproducibilidad mediante semillas fijas y versionado de datos y modelos.

Para procesar observaciones de cualquier duración sin cargar el dataset completo en memoria, se implementó un flujo de procesamiento en \textit{streaming} que divide los datos en bloques jerárquicos: \textbf{\textit{chunks}} (bloques temporales grandes determinados por la memoria disponible, típicamente segundos a minutos de observación) y \textbf{\textit{slices}} (segmentos temporales pequeños dentro de cada chunk, típicamente 100--1000 ms, que constituyen la unidad básica de detección). Este sistema calcula dinámicamente el tamaño óptimo de cada bloque basándose en la memoria disponible (RAM y GPU), aplica políticas de presupuesto inteligente que reservan recursos para operaciones de \textit{overhead}, y garantiza contigüidad temporal quirúrgica mediante validaciones estrictas y solapamiento controlado. Esta aproximación permite procesar observaciones de cualquier duración sin desbordamientos de memoria, manteniendo simultáneamente la precisión científica requerida para la localización precisa de eventos FRB.

% La Figura~\ref{fig:workflow-src} proporciona una representación esquemática de la arquitectura de DRAFTS++, integrando el flujo principal y los servicios transversales que aseguran consistencia y reproducibilidad.

% \begin{figure}[H]
% \centering
% \begingroup\shorthandoff{<>}% desactivar atajos de babel para < y > dentro de TikZ
% \resizebox{\textwidth}{!}{%
% \begin{tikzpicture}[
%     node distance=1.0cm and 1.6cm,
%     stage/.style={rectangle, draw, fill=blue!20, text width=2.7cm, text centered, minimum height=0.7cm, font=\small},
%     support/.style={rectangle, draw, fill=gray!20, text width=2.7cm, text centered, minimum height=0.6cm, font=\small, rounded corners},
%     arrow/.style={-Stealth, thick, shorten >=2pt}
% ]

% % Flujo principal por etapas (de izquierda a derecha)
% \node[stage] (in) {input/\\Ingesta};
% \node[stage, right=of in] (pp) {preprocessing/\\Preprocesamiento};
% \node[stage, right=of pp] (md) {models/\\Modelos};
% \node[stage, right=of md] (dt) {detection/\\Detección};
% \node[stage, right=of dt] (an) {analysis/\\Análisis};
% \node[stage, right=of an] (vz) {visualization/\\Visualización};
% \node[stage, right=of vz] (out) {output/\\Artefactos};

% \draw[arrow] (in) -- (pp);
% \draw[arrow] (pp) -- (md);
% \draw[arrow] (md) -- (dt);
% \draw[arrow] (dt) -- (an);
% \draw[arrow] (an) -- (vz);
% \draw[arrow] (vz) -- (out);

% % Módulos transversales de soporte (debajo)
% \node[support, below=3.2cm of md] (core) {core/\\Utilidades y Orquestación};
% \node[support, left=1.8cm of core] (cfg) {config/\\Configuración};
% \node[support, right=1.8cm of core] (log) {logging/\\Registro};
% \node[support, below=2.2cm of core] (scr) {scripts/\\CLI y Entradas};

% % Conexiones (líneas punteadas) desde soporte a etapas
% % Conexiones (desde borde superior de soporte al borde inferior de etapas)
% \draw[arrow, dashed] (core.north) -- (in.south);
% \draw[arrow, dashed] (core.north) -- (pp.south);
% \draw[arrow, dashed] (core.north) -- (md.south);
% \draw[arrow, dashed] (core.north) -- (dt.south);
% \draw[arrow, dashed] (core.north) -- (an.south);
% \draw[arrow, dashed] (core.north) -- (vz.south);

% \draw[arrow, dashed] (cfg.north) -- (in.south);
% \draw[arrow, dashed] (cfg.north) -- (pp.south);
% \draw[arrow, dashed] (cfg.north) -- (md.south);
% \draw[arrow, dashed] (cfg.north) -- (dt.south);
% \draw[arrow, dashed] (cfg.north) -- (an.south);
% \draw[arrow, dashed] (cfg.north) -- (vz.south);

% \draw[arrow, dashed] (log.north) -- (md.south);
% \draw[arrow, dashed] (log.north) -- (dt.south);
% \draw[arrow, dashed] (log.north) -- (an.south);

% \draw[arrow, dashed] (scr.north) -- (in.south);
% \draw[arrow, dashed] (scr.north) -- (pp.south);
% \draw[arrow, dashed] (scr.north) -- (md.south);
% \draw[arrow, dashed] (scr.north) -- (dt.south);
% \draw[arrow, dashed] (scr.north) -- (an.south);
% \draw[arrow, dashed] (scr.north) -- (vz.south);

% \end{tikzpicture}}
% \endgroup
% \caption[Arquitectura modular DRAFTS++]{Arquitectura modular del pipeline DRAFTS++ basada en la estructura de carpetas en \texttt{src/}: flujo principal (ingesta $\to$ preprocesamiento $\to$ modelos $\to$ detección $\to$ análisis $\to$ visualización $\to$ artefactos) y módulos transversales de soporte (\texttt{core/}, \texttt{config/}, \texttt{logging/}, \texttt{scripts/}). Esta figura introduce la construcción de DRAFTS++ como \textit{pipeline} productivo y eficiente, sin incluir aún la extensión de alta frecuencia.}
% \label{fig:workflow-src}
% \end{figure}

\subsubsection{Entrada de datos y streaming continuo}

\textbf{Ingesta multi-formato automática.} El sistema reconoce y lee automáticamente múltiples formatos (FITS, PSRFITS, SIGPROC Filterbank) sin configuración manual. Parsea headers para extraer parámetros observacionales (frecuencias, resolución temporal, polarización), ajustando dinámicamente la configuración del pipeline. Incorpora detección automática de archivos mediante escaneo de directorios, eliminando especificación manual de rutas.

\textbf{Streaming robusto con control de buffer.} Para prevenir crecimiento descontrolado de memoria, el sistema implementa límite estricto en el buffer interno: $N_{b,\max} = \max(2 N_c, 10^7)$. Si el buffer excede este límite, se fuerza emisión de chunk de emergencia, garantizando uso de memoria acotado incluso en archivos con estructura irregular o gaps temporales.

\textbf{Continuidad temporal entre archivos.} El pipeline procesa secuencialmente múltiples archivos de una sesión manteniendo continuidad temporal mediante verificación de contigüidad precisa, solucionando cortes que antes generaban detecciones duplicadas o pérdidas.



\subsubsection{Preprocesamiento y normalización de geometría}

El preprocesamiento transforma datos crudos heterogéneos (diferentes telescopios, formatos, resoluciones) en representaciones homogéneas compatibles con los modelos de deep learning:

\textbf{Decimación adaptativa.} Reduce tasa de muestreo temporal ($r_t$) y espectral ($r_\nu$) mediante promediado, disminuyendo volumen sin comprometer detección de transientes milisegundo. La resolución temporal decimada es $\Delta t_d = \Delta t_0 \times r_t$, y la longitud de slice se calcula como $L_s = \lfloor (\tau_s / 1000) / \Delta t_d + 0.5 \rfloor$, donde $\tau_s$ es la duración objetivo (típicamente 100--1000 ms).

\textbf{Construcción del cubo DM--tiempo.} Se implementa dedispersión acelerada en GPU (Numba CUDA/PyTorch) con fallback a CPU, generando cubo de forma $(3, H_{\text{DM}}, N_t)$ con tres planos (total, medio, diferencia) según prácticas estándar. El retardo por canal se calcula mediante $\delta_j = \lfloor 4.148808 \times 10^{3} \times \text{DM} \times (\nu_j^{-2} - \nu_{\max}^{-2}) / \Delta t_d \rfloor$.

\textbf{Normalización y transformaciones.} Normalización robusta con remoción de tendencias, clipping de outliers, y escalado a rango compatible con modelos. Transformaciones bidireccionales entre coordenadas de píxeles (512$\times$512) y valores físicos (DM, tiempo), y mapeo de offsets a tiempos absolutos.

\textbf{Solapamiento controlado y continuidad temporal quirúrgica.} Para evitar pérdidas cuando un pulso dispersado cruza límites entre chunks, el sistema procesa cada chunk $k$ incluyendo overlap de $\mathcal{O}_d$ muestras a cada lado, donde $\mathcal{O}_d \geq \Delta t_{\max}$ garantiza que cualquier pulso queda completamente contenido en al menos un chunk. Tras dedispersar, se recortan las regiones de overlap mediante extracción de ventana válida $W_k = [\mathcal{O}_d, N_c - \mathcal{O}_d]$. La concatenación de ventanas válidas $\bigcup W_k = \mathcal{T}$ reconstruye la serie temporal original sin discontinuidades ni duplicación, manteniendo memoria acotada a un chunk más overlap independientemente de la duración total de la observación.

\subsubsection{Planificación de recursos y gestión de memoria}\label{sec:gpu-memory}

El sistema implementa un motor de planificación de recursos de múltiples capas que garantiza procesamiento sin errores OOM: \textbf{(i)} presupuesto adaptativo de memoria calculado dinámicamente, \textbf{(ii)} chunking jerárquico (temporal y en DM) para casos extremos, \textbf{(iii)} validación explícita antes de asignaciones grandes, y \textbf{(iv)} fallback automático GPU$\to$CPU. Esta arquitectura permite procesar archivos de cualquier tamaño y rango de DM manteniendo precisión científica completa.

\paragraph{Presupuesto adaptativo de memoria (3 fases)}

El sistema calcula dinámicamente el tamaño óptimo de chunks basándose en el costo de dedispersión y restricciones físicas, estructurado en tres fases:

\textbf{Fase A (Costo):} Calcula costo por muestra temporal en el cubo DM--tiempo: $C_s = 3 H_{\text{DM}} \times 4$ bytes, donde $H_{\text{DM}} = \text{DM}_{\max} - \text{DM}_{\min} + 1$ (altura del cubo), factor $3$ (tres planos: total, medio, diferencia), y $4$ bytes (float32).

\textbf{Fase B (Capacidad):} Calcula memoria utilizable aplicando factores de seguridad sobre RAM/VRAM disponible ($\alpha_R = 0.25$, $\alpha_V = 0.7$, overhead $\phi_o = 1.3$), obteniendo capacidad máxima $N_{\max} = \lfloor M_u / C_s \rfloor$.

\textbf{Fase C (Restricción física):} Calcula tamaño mínimo requerido $N_{\min} = \mathcal{O}_d + L_s$, donde $\mathcal{O}_d = \lfloor \lceil \Delta t_{\max} / \Delta t_0 \rceil / r_t \rfloor$ es el solapamiento necesario para garantizar continuidad.

\textbf{Decisión final:} Si $N_{\max} > N_{\min}$ (escenario \textit{Ideal}), usa chunk máximo permitido; si $N_{\max} \leq N_{\min}$ (escenario \textit{Extremo}), usa chunk mínimo y activa chunking en DM. El chunk final se alinea a múltiplo de $L_s$: $N_c = \max(L_s, \lfloor N / L_s \rfloor \times L_s)$.

\paragraph{Límite del cubo DM-tiempo y estrategias de resiliencia}

El sistema implementa límite configurable $\tau_{\text{cube}}$ (por defecto 2 GB) que restringe el cubo DM--tiempo resultante. El tamaño del cubo con overlap es $S_{\text{cube}} = 3 H_{\text{DM}} (N_c + 2\mathcal{O}_d) \times 4$ bytes. Si excede límite máximo $S_{\max} = 4 \tau_{\text{cube}}$ GB, el sistema activa automáticamente estrategias de resiliencia:

\textbf{(i) Chunking jerárquico en dominio DM:} Si el cubo excede $\tau_{\text{DM}}$ (por defecto 16 GB), el rango de DM se divide en sub-rangos: $H_{c,\text{DM}} = \max(100, \lfloor \tau_{\text{DM}} \times 2^{30} / (3 N_c \times 4) \rfloor)$, procesándose secuencialmente $N_{c,\text{DM}} = \lceil H_{\text{DM}} / H_{c,\text{DM}} \rceil$ chunks de DM.

\textbf{(ii) Recuperación resiliente mediante chunking temporal:} Si el cubo excede $S_{\max}$ incluso tras restricciones preventivas, el chunk temporal se divide en sub-chunks de tamaño $W_{c,\text{temp}} = \max(1000, \lfloor S_{\max} / (3 H_{\text{DM}} \times 4) \rfloor)$, procesándose $N_{c,\text{temp}} = \lceil N_c / W_{c,\text{temp}} \rceil$ sub-chunks con dedispersión completa cada uno. Esta estrategia garantiza que el pipeline nunca falle por OOM.

\textbf{(iii) Validación explícita de memoria:} Antes de asignaciones grandes, se valida $S_{\text{GB}} = S / 2^{30} \leq \tau_e$ (umbral error = 16 GB). Si $S_{\text{GB}} > \tau_w = 8$ GB, se emite advertencia pero se permite la asignación.

% \subsubsection{Integración orquestada de técnicas estándar}

% Para construir un pipeline completo y operativo, \textbf{DRAFTS++} integra múltiples técnicas estándar de la literatura mediante interfaces bien definidas y flujos automatizados. La contribución radica en la orquestación end-to-end que conecta estas técnicas en un sistema robusto, reproducible y escalable. Las integraciones principales incluyen:

% \textbf{Modelos de deep learning:} Inferencia automática de CenterNet (detección) y ResNet18 (clasificación) pre-entrenados, con gestión automática de carga de modelos, preparación de tensores, inferencia en GPU con fallback a CPU, y paso fluido de candidatos entre etapas mediante estructura de datos común (\texttt{Candidate}).

% \textbf{Cálculo de SNR PRESTO:} Integración de algoritmos PRESTO~\cite{Ransom2011_PRESTO} con \textit{matched filtering} boxcar ($\mathcal{W} = \{1, 2, 3, 4, 6, 9, 14, 20, 30\}$ muestras), normalización robusta mediante detrending por bloques, y factor de corrección estándar 1.148, garantizando compatibilidad con umbrales de la comunidad astronómica.

% \textbf{Dedispersión:} Algoritmos estándar con cálculo de retardo $\delta_j = \lfloor 4.148808 \times 10^{3} \times \text{DM} \times (\nu_j^{-2} - \nu_{\max}^{-2}) / \Delta t_d \rfloor$, implementación acelerada en GPU (Numba CUDA/PyTorch) con fallback a CPU, y construcción de cubo DM--tiempo con tres planos (total, medio, diferencia) según prácticas estándar.

% \textbf{Transformaciones de coordenadas:} Mapeo bidireccional entre coordenadas de píxeles (512$\times$512) y valores físicos (DM en pc cm$^{-3}$, tiempo en segundos), y conversión de offsets de muestra a tiempos absolutos.

% \textbf{Decimación adaptativa:} Downsampling temporal (suma estilo PRESTO) y espectral (promedio), con factores $r_t$ y $r_\nu$ calculados dinámicamente según características del instrumento.

% \textbf{Productos de polarización:} Transformaciones Stokes estándar ($L = \sqrt{Q^2 + U^2}$, $V_{\text{abs}} = |V|$) con detección automática de formato (IQUV, AABB, etc.) para modo HF-PoL.

% \textbf{Estimación de ruido:} Métodos robustos con IQR (factor 1.349), cálculo de significancia estadística con corrección por múltiples pruebas, y filtrado de falsos positivos.

% \textbf{Trazabilidad:} Sistema de \textit{logging} estructurado que registra metadatos completos (tiempo absoluto, DM, SNR, probabilidades, coordenadas), genera salidas reproducibles (CSV, PNG), y garantiza reproducibilidad mediante semillas fijas y versionado de configuraciones. 

% =============================================================
% Componente 2: Extensión a Alta Frecuencia
% =============================================================
\subsection{Componente 2: Extensión a Alta Frecuencia}

Este componente constituye la \textbf{contribución metodológica novedosa de mayor impacto científico} de esta tesis: la solución al problema de detección de FRBs en el régimen milimétrico (30--100 GHz), donde la compresión de la firma dispersiva (discutida en detalle en la Sección 2.5 del marco conceptual) limita la efectividad del pipeline clásico basado en mapas DM{-}tiempo. Como se demuestra empíricamente en la validación (Sección 5.2.1), el pipeline DRAFTS-clásico falla completamente en alta frecuencia ($\sim$0\% de recall con configuración estándar en 86 GHz), requiriendo un enfoque alternativo.

El sistema no introduce nuevos modelos de aprendizaje profundo: conserva \textbf{CenterNet} y \textbf{ResNet18}, pero añade una capa de decisión física que permite conmutar automáticamente entre dos modos operativos de detección según el régimen frecuencial. Ambos modos comparten el mismo flujo de clasificación y validación, garantizando consistencia, reproducibilidad y trazabilidad dentro de la arquitectura unificada. El criterio físico que guía la transición entre modos se basa en el retardo dispersivo máximo entre los extremos de banda $\Delta t_{\mathrm{ms}} = 4.148808 \times 10^{3}\,\mathrm{DM}\,\big(\nu_{\mathrm{low}}^{-2} - \nu_{\mathrm{high}}^{-2}\big)$ comparado con la resolución temporal efectiva $t_{\mathrm{samp}}$: cuando $\Delta t_{\mathrm{ms}} \le \alpha\, t_{\mathrm{samp}}$ (con $\alpha$ de seguridad en el rango 1.5--2.0), el sistema conmuta automáticamente a la solución propuesta descrita a continuación.

%Esta estrategia constituye una extensión natural del Componente 1: se emplea \textbf{exactamente el mismo DRAFTS++ sin modificaciones}, preservando la arquitectura y el \emph{workflow} clásico (detección en espacio DM{-}tiempo con CenterNet pre-entrenado y clasificación con ResNet18 pre-entrenado), con el propósito de \textit{medir su capacidad base} en regímenes de alta frecuencia. El objetivo es doble: (i) establecer la sensibilidad y robustez mínima alcanzable sin introducir nuevas estrategias de detección, y (ii) cuantificar objetivamente el punto a partir del cual las estrategias específicas de alta frecuencia (Estrategia 2) superan al flujo clásico en eficacia operativa. El criterio físico de resolubilidad se expresa mediante el retardo dispersivo máximo entre los extremos de banda,
%\[
%\%Delta t_{\mathrm{ms}} = 4.148808 \times 10^{3}\,\, \mathrm{DM}\,\big(\nu_{\mathrm{low}}^{-2}-%\nu_{\mathrm{high}}^{-2}\big),
%\]

%\noindent donde:
%\begin{itemize}
    %\item $\Delta t_{\mathrm{ms}}$: retardo dispersivo entre los extremos de banda, en milisegundos.
    %\item $\mathrm{DM}$: medida de dispersión de la línea de visión, en pc\,cm$^{-3}$.
    %\item $\nu_{\mathrm{low}}, \, \nu_{\mathrm{high}}$: frecuencias de borde inferior y superior de la banda, en GHz.
    %\item $t_{\mathrm{samp}}$: resolución temporal efectiva de muestreo del dato, en ms.
    %\item $\alpha$: factor de seguridad adimensional usado en el criterio de resolubilidad (típicamente 1.5--2.0).
%\end{itemize}
%comparado con la resolución temporal efectiva $t_{\mathrm{samp}}$. Cuando $\Delta t_{\mathrm{ms}} > \alpha\, t_{\mathrm{samp}}$ (con $\alpha$ de seguridad en el rango 1.5–2.0), el \textit{bow–tie} permanece resoluble y la detección en DM{-}tiempo sigue siendo pertinente; si $\Delta t_{\mathrm{ms}} \le \alpha\, t_{\mathrm{samp}}$, la firma se comprime y el mapa DM{-}tiempo pierde contraste, anticipándose una disminución de sensibilidad. La validación consiste, por tanto, en aplicar el flujo sin modificaciones sobre ventanas en las que $\Delta t_{\mathrm{ms}}$ sea resoluble y medir sensibilidad, tasa de falsos positivos y estabilidad temporal del detector; este resultado sirve de referencia objetiva para las estrategias alternativas descritas a continuación.


\subsubsection{Pipeline HF Multi-Fase: Matched Filtering y Validación Polarimétrica}

Cuando el retardo dispersivo se vuelve comparable o inferior a la resolución temporal ($\Delta t_{\mathrm{ms}} \le \alpha\, t_{\mathrm{samp}}$), el patrón DM{-}tiempo pierde contraste y el método clásico (baseline) deja de ser efectivo. En este régimen, la representación más informativa pasa a ser el perfil temporal, no la morfología dispersiva en el espacio DM{-}tiempo. La solución adoptada es un \textbf{pipeline híbrido de tres fases} que combina detección clásica (matched filtering) con clasificación mediante deep learning, activándose condicionalmente cuando $\Delta t_{\mathrm{ms}} \le \alpha\, t_{\mathrm{samp}}$ mediante criterio físico automatizado.

El pipeline se estructura en las siguientes fases:

\paragraph{Fase 1: Detección de picos SNR mediante Matched Filtering Boxcar}

La primera fase implementa detección de picos SNR mediante técnicas estándar de matched filtering con banco de kernels boxcar, replicando la práctica consolidada en PRESTO~\cite{Ransom2011_PRESTO} y CHIME/FRB~\cite{CHIME_FRB_Collaboration_2020}:

\textbf{(i)} Integración espectral del waterfall $W(t, \nu)$ para obtener serie temporal $s(t) = \frac{1}{N_\nu} \sum_{\nu} W(t, \nu)$. 

\textbf{(ii)} Normalización robusta mediante detrending por bloques y estimación de ruido con factor de corrección PRESTO estándar (1.148).

\textbf{(iii)} Matched filtering con banco de boxcars $\mathcal{W} = \{1, 2, 3, 4, 6, 9, 14, 20, 30\}$ muestras, calculando $\mathrm{SNR}(t) = \max_{w \in \mathcal{W}} (s * b_w)(t)$.

\textbf{(iv)} Extracción de picos donde $\mathrm{SNR}(t_i) \geq T$ (típicamente $T = 5$--$7\sigma$) con separación mínima entre detecciones.

Esta fase garantiza sensibilidad recuperando pulsos sin depender de la firma dispersiva.

\paragraph{Fase 2: Validación Polarimétrica (Opcional)}

Cuando el dataset incluye productos Stokes (Q, U), se aplica validación polarimétrica para filtrar RFI no polarizada. Para cada pico $t_i$ detectado, se calcula polarización lineal $L(t) = \sqrt{Q^2(t) + U^2(t)}$ y se evalúa $\mathrm{SNR}_{\mathrm{L}}(t_i)$ mediante matched filtering. El candidato se valida si $\mathrm{SNR}_{\mathrm{L}}(t_i) \geq T$, explotando la alta linealidad observada en FRBs~\cite{Michilli2018} versus RFI típicamente no polarizada. Si no hay productos Stokes, todos los picos pasan a Fase 3.

\paragraph{Fase 3: Clasificación Dual mediante ResNet18}

Para cada candidato validado, se realiza clasificación CNN dual proporcionando especificidad adicional:

\textbf{Fase 3a: Clasificación en Intensidad.} Se extrae parche tiempo--frecuencia (512$\times$512) centrado en $t_i$. Se evalúa rejilla local de DMs ($\sim$20--50 valores) y se dedispersa, obteniendo DM óptimo mediante $\mathrm{DM}^* = \arg\max_{\mathrm{DM}_k} \mathrm{SNR}_{\mathrm{dedis}}(\mathrm{DM}_k, t_i)$. El parche dedispersado se normaliza y clasifica con ResNet18 pre-entrenado (Componente 1), obteniendo $p_{\mathrm{I}} \in [0,1]$.

\textbf{Fase 3b: Clasificación en Polarización Lineal (Opcional).} Si hay productos Stokes, se construye parche $L$ dedispersado a $\mathrm{DM}^*$ y se clasifica con ResNet18, obteniendo $p_{\mathrm{L}} \in [0,1]$.

\textbf{Lógica de decisión.} El sistema implementa dos modos: \textbf{STRICT} (requiere $(p_{\mathrm{I}} \geq \theta) \land (p_{\mathrm{L}} \geq \theta)$, maximiza especificidad) y \textbf{PERMISSIVE} (requiere $(p_{\mathrm{I}} \geq \theta) \lor (p_{\mathrm{L}} \geq \theta)$, maximiza sensibilidad, por defecto), con $\theta = 0.6$.

\textbf{Integración en arquitectura unificada.} El sistema conmuta automáticamente de CenterNet (modo clásico) a matched filtering (Fase 1) según criterio físico, integra validación polarimétrica (Fase 2) y clasificación dual (Fases 3a--3b), y regresa a validación física estándar y emisión de artefactos estandarizados, garantizando consistencia y trazabilidad en todos los regímenes frecuenciales.

\paragraph{Justificación y fundamentos del diseño}

La arquitectura del pipeline HF se fundamenta en: \textbf{(i)} matched filtering óptimo en ruido AWGN, aproximado mediante boxcars con pérdida $<10\%$ pero complejidad muy inferior, \textbf{(ii)} adaptación al régimen físico de alta frecuencia donde $\Delta t \propto \nu^{-2}$ es pequeño y las decisiones basadas en perfiles temporales son más efectivas que morfología DM--tiempo, \textbf{(iii)} robustez a RFI explotando alta linealidad observada en FRBs~\cite{Michilli2018,CHIME_FRB_Collaboration_2020} versus RFI no polarizada, \textbf{(iv)} clasificación dual con integración de evidencia mediante modos STRICT/PERMISSIVE para balance sensibilidad--especificidad, y \textbf{(v)} compatibilidad con estándares PRESTO/CHIME y reutilización de ResNet18 del Componente 1 para consistencia.

El pipeline HF se integra en DRAFTS++ mediante activación condicional automática (criterio $\Delta t_{\mathrm{ms}} \le \alpha\, t_{\mathrm{samp}}$), conmutando entre modo clásico (CenterNet) y modo HF-PoL (matched filtering + clasificación dual). Ambos modos comparten flujo de validación y emisión de artefactos estandarizados, garantizando consistencia y trazabilidad. Los detalles operativos se detallan en el Algoritmo~\ref{alg:hf-snr-class}.

% \begin{table}[H]
% \centering
% \footnotesize
% \renewcommand{\arraystretch}{1.3}
% \setlength{\tabcolsep}{3pt}
% \caption{Hiperparámetros del Pipeline HF Multi{-}Fase (Solución Propuesta)}
% \label{tab:hf-hyperparameters}
% \resizebox{0.85\textwidth}{!}{%
% \begin{tabular}{p{3.5cm} p{2.0cm} p{4.0cm}}
% \toprule
% \textbf{Fase} & \textbf{Parámetro} & \textbf{Valor Típico} \\
% \midrule
% \multicolumn{3}{c}{\textbf{Fase 1: Boxcar Matched Filtering}} \\
% \midrule
% Banco de anchos & $\mathcal{W}$ & $\{1, 2, 3, 4, 6, 9, 14, 20, 30\}$ muestras \\
% Umbral SNR & $T$ & $5$--$7\,\sigma$ \\
% Separación mínima & $\Delta t_{\min}$ & 10--20 muestras \\
% \midrule
% \multicolumn{3}{c}{\textbf{Fase 2: Validación Polarimétrica}} \\
% \midrule
% Factor consistencia & $\beta$ & 0.5--0.7 \\
% \midrule
% \multicolumn{3}{c}{\textbf{Fases 3a-3b: Clasificación Dual}} \\
% \midrule
% Umbral clasificación & $\theta_{\mathrm{class}}$ & 0.6 \\
% Modo decisión & STRICT\mbox{/}PERMISSIVE & PERMISSIVE \mbox{(por defecto)} \\
% Rejilla DM local & $\mathrm{DM}_k$ & 20--50 valores \\
% \bottomrule
% \end{tabular}%
% }%
% \end{table}

\begin{otherlanguage*}{english}
\begin{algorithm}[H]
\caption{Pipeline HF Multi{-}Fase: Matched Filtering + Validación Polarimétrica + Clasificación Dual}
\label{alg:hf-snr-class}
\begin{algorithmic}[1]
\Require Serie temporal $s(t)$, productos Stokes (I, Q, U) si disponibles, umbral $T$, separación $\Delta t_{\min}$, conjunto de anchos $\mathcal{W}$, rejilla local de DM, modo de decisión (STRICT/PERMISSIVE)
\Ensure Candidatos validados con $\{t_{\mathrm{evt}},\, \mathrm{SNR},\, \mathrm{DM}^*,\, p_{\mathrm{I}},\, p_{\mathrm{L}}\}$

\State \textbf{FASE 1: Boxcar Matched Filtering}
\State Normalizar $s(t)$ mediante detrending y normalización robusta local
\State Calcular $\mathrm{SNR}(t) = \max_{w\in\mathcal{W}} (s * b_w)(t) / \sqrt{w}$ con $\mathcal{W} = \{1,2,3,4,6,9,14,20,30\}$
\State Extraer picos $\{t_i\}$ donde $\mathrm{SNR}(t_i) \geq T$ y $|t_i - t_j| \geq \Delta t_{\min}$

\For{cada candidato $t_i$}
    \State \textbf{FASE 2: Validación Polarimétrica (si disponible)}
    \If{productos Stokes Q, U disponibles}
        \State Calcular $L(t) = \sqrt{Q^2(t) + U^2(t)}$
        \State Calcular $\mathrm{SNR}_{\mathrm{L}}(t_i)$ en polarización lineal
        \If{$\mathrm{SNR}_{\mathrm{L}}(t_i) < \beta \cdot \mathrm{SNR}_{\mathrm{I}}(t_i)$ con $\beta \approx 0.5$--0.7}
            \State \textbf{continue} \Comment{Descartar por baja coherencia polarimétrica}
        \EndIf
    \EndIf
    
    \State \textbf{FASE 3a: Estimación de DM y Clasificación en Intensidad}
    \State Extraer parche tiempo{-}frecuencia centrado en $t_i$
    \State Evaluar rejilla local $\{\mathrm{DM}_k\}$ y obtener $\mathrm{DM}^* = \arg\max_{\mathrm{DM}_k} \mathrm{SNR}_{\mathrm{dedis}}(\mathrm{DM}_k, t_i)$
    \State Dedispersar parche a $\mathrm{DM}^*$ y normalizar (sustracción tendencia, clipping, escalado min{-}max)
    \State Inferir con ResNet18: $p_{\mathrm{I}} = \text{classify}(\text{patch}_{\mathrm{I}})$
    
    \State \textbf{FASE 3b: Clasificación en Polarización Lineal (si disponible)}
    \If{productos Stokes Q, U disponibles}
        \State Construir parche L dedispersado a $\mathrm{DM}^*$ y normalizar
        \State Inferir con ResNet18: $p_{\mathrm{L}} = \text{classify}(\text{patch}_{\mathrm{L}})$
        
        \If{modo STRICT}
            \State $\text{valid} = (p_{\mathrm{I}} \geq \theta_{\mathrm{class}}) \land (p_{\mathrm{L}} \geq \theta_{\mathrm{class}})$
        \ElsIf{modo PERMISSIVE}
            \State $\text{valid} = (p_{\mathrm{I}} \geq \theta_{\mathrm{class}}) \lor (p_{\mathrm{L}} \geq \theta_{\mathrm{class}})$
        \EndIf
    \Else
        \State $\text{valid} = (p_{\mathrm{I}} \geq \theta_{\mathrm{class}})$ \Comment{Solo intensidad disponible}
    \EndIf
    
    \If{$\text{valid}$ y $\mathrm{DM}^* > 0$ y anchura temporal finita}
        \State Emitir candidato validado: $(t_{\mathrm{evt}} = t_i,\, \mathrm{SNR}(t_i),\, \mathrm{DM}^*,\, p_{\mathrm{I}},\, p_{\mathrm{L}})$
    \EndIf
\EndFor
\end{algorithmic}
\end{algorithm}
\end{otherlanguage*}

% La Figura~\ref{fig:hf-snr-detection-detail} ilustra el flujo operativo detallado del pipeline HF, mostrando cómo los productos de las Fases 1 y 2 alimentan la clasificación dual ResNet18 (Fases 3a-3b), y cómo la decisión final de detección integra evidencia probabilística de ambas polarizaciones. Este esquema operativo representa la implementación concreta del Algoritmo~\ref{alg:hf-snr-class}, destacando la reutilización de la arquitectura ResNet18 pre-entrenada del Componente 1 en un contexto de detección adaptado al régimen de alta frecuencia.

% \begin{figure}[H]
% \centering
% \includegraphics[width=0.98\textwidth]{figures/DRAFTS-HF-SNR/SNR_HF.png}
% \caption[Arquitectura del Pipeline HF Multi-Fase: Integración de Detección Clásica y Deep Learning]{Figura~\ref{fig:hf-snr-detection-detail}. Arquitectura del pipeline HF multi-fase (modo HF-PoL) integrando detección clásica con deep learning. Fase 1: boxcar matched filtering en Stokes I genera candidatos con $\mathrm{SNR}_{\mathrm{I}} \geq T$ (5--7$\sigma$). Fase 2: validación polarimétrica opcional (SNR en L). Fase 3a: clasificación ResNet18 en intensidad dedispersada ($p_{\mathrm{I}}$). Fase 3b: clasificación ResNet18 en polarización lineal ($p_{\mathrm{L}}$). Decisión final: modo STRICT requiere $p_{\mathrm{I}} \geq \theta$ AND $p_{\mathrm{L}} \geq \theta$; modo PERMISSIVE requiere $p_{\mathrm{I}} \geq \theta$ OR $p_{\mathrm{L}} \geq \theta$. El flujo integra matched filtering (sensibilidad) con clasificación dual CNN (especificidad).}
% \label{fig:hf-snr-detection-detail}
% \end{figure}

% \begin{figure}[H]
% \centering
% \resizebox{0.98\textwidth}{!}{%
% \begin{tikzpicture}[
%     node distance=1.1cm and 1.9cm,
%     stage/.style={rectangle, draw, fill=blue!20, text width=2.4cm, text centered, minimum height=0.8cm, font=\scriptsize},
%     decision/.style={diamond, draw, fill=yellow!20, aspect=2.5, text width=2.5cm, text centered, inner sep=2pt, font=\scriptsize},
%     phase/.style={rectangle, draw, fill=green!20, text width=2.4cm, text centered, minimum height=0.8cm, font=\scriptsize},
%     arrow/.style={-Stealth, thick}
% ]

% % Nodos principales
% \node[stage] (input) {Archivo\\HF};
% \node[decision, right=of input] (cond) {$\Delta t_{\mathrm{ms}} > \alpha\,t_{\mathrm{samp}}$?};
% \node[phase, below right=of cond] (fase1) {FASE 1:\\Boxcar Matching};
% \node[stage, above right=of cond] (dmmap) {Pipeline\\Clásico};
% \node[decision, right=of fase1] (fase2check) {¿Stokes\\Q, U?};
% \node[phase, below=0.6cm of fase2check] (fase2) {FASE 2:\\Valid. Polar.};
% \node[phase, right=of fase2check] (fase3a) {FASE 3a:\\Clasif. I};
% \node[phase, below=0.6cm of fase3a] (fase3b) {FASE 3b:\\Clasif. L};
% \node[stage, right=of fase3a] (val) {Validación\\Física};
% \node[stage, right=of val] (out) {Artefactos\\Estandarizados};

% % Flujo
% \draw[arrow] (input) -- (cond);
% \draw[arrow] (cond) -- node[above, font=\tiny] {Sí} (dmmap);
% \draw[arrow] (cond) -- node[below, font=\tiny] {No} (fase1);
% \draw[arrow] (fase1) -- (fase2check);
% \draw[arrow] (fase2check) -- node[left, font=\tiny] {Sí} (fase2);
% \draw[arrow] (fase2check) -- node[above, font=\tiny] {No} (fase3a);
% \draw[arrow] (fase2) -- (fase3a);
% \draw[arrow] (fase3a) -- node[left, font=\tiny] {Si Q,U} (fase3b);
% \draw[arrow] (fase3a) -- (val);
% \draw[arrow] (fase3b) -- (val);
% \draw[arrow] (dmmap) |- (val);
% \draw[arrow] (val) -- (out);

% \end{tikzpicture}}
% \caption[Integración del Pipeline HF en DRAFTS++: Activación Condicional por Régimen Frecuencial]{Figura~\ref{fig:hf-snr-branch}. Integración del pipeline HF multi-fase (Componente 2) en DRAFTS++ mediante activación condicional automática (criterio $\Delta t_{\mathrm{ms}} \le \alpha\,t_{\mathrm{samp}}$). El sistema conmuta del modo DRAFTS-clásico (LF, CenterNet) al modo HF-PoL (HF, matched filtering + clasificación dual ResNet18 I+L). La rama HF implementa 4 fases antes de regresar a validación física unificada. Los módulos polarimétricos (Fases 2 y 3b) son opcionales según disponibilidad de productos Stokes.}
% \label{fig:hf-snr-branch}
% \end{figure}